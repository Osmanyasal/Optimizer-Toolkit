#include <cstdint>
namespace optkit::amd64{
	enum class fam11h : uint64_t {
		DISPATCHED_FPU = 0x0, // Dispatched FPU Operations
		DISPATCHED_FPU__MASK__AMD64_FAM11H_DISPATCHED_FPU__OPS_ADD = 0x1, // Add pipe ops excluding load ops and SSE move ops
		DISPATCHED_FPU__MASK__AMD64_FAM11H_DISPATCHED_FPU__OPS_MULTIPLY = 0x2, // Multiply pipe ops excluding load ops and SSE move ops
		DISPATCHED_FPU__MASK__AMD64_FAM11H_DISPATCHED_FPU__OPS_STORE = 0x4, // Store pipe ops excluding load ops and SSE move ops
		DISPATCHED_FPU__MASK__AMD64_FAM11H_DISPATCHED_FPU__OPS_ADD_PIPE_LOAD_OPS = 0x8, // Add pipe load ops and SSE move ops
		DISPATCHED_FPU__MASK__AMD64_FAM11H_DISPATCHED_FPU__OPS_MULTIPLY_PIPE_LOAD_OPS = 0x10, // Multiply pipe load ops and SSE move ops
		DISPATCHED_FPU__MASK__AMD64_FAM11H_DISPATCHED_FPU__OPS_STORE_PIPE_LOAD_OPS = 0x20, // Store pipe load ops and SSE move ops
		DISPATCHED_FPU__MASK__AMD64_FAM11H_DISPATCHED_FPU__ALL = 0x3f, // All sub-events selected
		CYCLES_NO_FPU_OPS_RETIRED = 0x1, // Cycles in which the FPU is Empty
		DISPATCHED_FPU_OPS_FAST_FLAG = 0x2, // Dispatched Fast Flag FPU Operations
		SEGMENT_REGISTER_LOADS = 0x20, // Segment Register Loads
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__ES = 0x1, // ES
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__CS = 0x2, // CS
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__SS = 0x4, // SS
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__DS = 0x8, // DS
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__FS = 0x10, // FS
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__GS = 0x20, // GS
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__HS = 0x40, // HS
		SEGMENT_REGISTER_LOADS__MASK__AMD64_FAM11H_SEGMENT_REGISTER_LOADS__ALL = 0x7f, // All sub-events selected
		PIPELINE_RESTART_DUE_TO_SELF_MODIFYING_CODE = 0x21, // Pipeline Restart Due to Self-Modifying Code
		PIPELINE_RESTART_DUE_TO_PROBE_HIT = 0x22, // Pipeline Restart Due to Probe Hit
		LS_BUFFER_2_FULL_CYCLES = 0x23, // LS Buffer 2 Full
		LOCKED_OPS = 0x24, // Locked Operations
		LOCKED_OPS__MASK__AMD64_FAM11H_LOCKED_OPS__EXECUTED = 0x1, // The number of locked instructions executed
		LOCKED_OPS__MASK__AMD64_FAM11H_LOCKED_OPS__CYCLES_SPECULATIVE_PHASE = 0x2, // The number of cycles spent in speculative phase
		LOCKED_OPS__MASK__AMD64_FAM11H_LOCKED_OPS__CYCLES_NON_SPECULATIVE_PHASE = 0x4, // The number of cycles spent in non-speculative phase (including cache miss penalty)
		LOCKED_OPS__MASK__AMD64_FAM11H_LOCKED_OPS__ALL = 0x7, // All sub-events selected
		RETIRED_CLFLUSH_INSTRUCTIONS = 0x26, // Retired CLFLUSH Instructions
		RETIRED_CPUID_INSTRUCTIONS = 0x27, // Retired CPUID Instructions
		DATA_CACHE_ACCESSES = 0x40, // Data Cache Accesses
		DATA_CACHE_MISSES = 0x41, // Data Cache Misses
		DATA_CACHE_REFILLS = 0x42, // Data Cache Refills from L2 or System
		DATA_CACHE_REFILLS__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS__SYSTEM = 0x1, // Refill from the Northbridge
		DATA_CACHE_REFILLS__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS__L2_SHARED = 0x2, // Shared-state line from L2
		DATA_CACHE_REFILLS__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS__L2_EXCLUSIVE = 0x4, // Exclusive-state line from L2
		DATA_CACHE_REFILLS__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS__L2_OWNED = 0x8, // Owned-state line from L2
		DATA_CACHE_REFILLS__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS__L2_MODIFIED = 0x10, // Modified-state line from L2
		DATA_CACHE_REFILLS__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS__ALL = 0x1f, // All sub-events selected
		DATA_CACHE_REFILLS_FROM_SYSTEM = 0x43, // Data Cache Refills from the System
		DATA_CACHE_REFILLS_FROM_SYSTEM__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS_FROM_SYSTEM__INVALID = 0x1, // Invalid
		DATA_CACHE_REFILLS_FROM_SYSTEM__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS_FROM_SYSTEM__SHARED = 0x2, // Shared
		DATA_CACHE_REFILLS_FROM_SYSTEM__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS_FROM_SYSTEM__EXCLUSIVE = 0x4, // Exclusive
		DATA_CACHE_REFILLS_FROM_SYSTEM__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS_FROM_SYSTEM__OWNED = 0x8, // Owned
		DATA_CACHE_REFILLS_FROM_SYSTEM__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS_FROM_SYSTEM__MODIFIED = 0x10, // Modified
		DATA_CACHE_REFILLS_FROM_SYSTEM__MASK__AMD64_FAM11H_DATA_CACHE_REFILLS_FROM_SYSTEM__ALL = 0x1f, // All sub-events selected
		DATA_CACHE_LINES_EVICTED = 0x44, // Data Cache Lines Evicted
		DATA_CACHE_LINES_EVICTED__MASK__AMD64_FAM11H_DATA_CACHE_LINES_EVICTED__INVALID = 0x1, // Invalid
		DATA_CACHE_LINES_EVICTED__MASK__AMD64_FAM11H_DATA_CACHE_LINES_EVICTED__SHARED = 0x2, // Shared
		DATA_CACHE_LINES_EVICTED__MASK__AMD64_FAM11H_DATA_CACHE_LINES_EVICTED__EXCLUSIVE = 0x4, // Exclusive
		DATA_CACHE_LINES_EVICTED__MASK__AMD64_FAM11H_DATA_CACHE_LINES_EVICTED__OWNED = 0x8, // Owned
		DATA_CACHE_LINES_EVICTED__MASK__AMD64_FAM11H_DATA_CACHE_LINES_EVICTED__MODIFIED = 0x10, // Modified
		DATA_CACHE_LINES_EVICTED__MASK__AMD64_FAM11H_DATA_CACHE_LINES_EVICTED__ALL = 0x1f, // All sub-events selected
		L1_DTLB_MISS_AND_L2_DTLB_HIT = 0x45, // Number of data cache accesses that miss in L1 DTLB and hit in L2 DTLB
		L1_DTLB_AND_L2_DTLB_MISS = 0x46, // Number of data cache accesses that miss both the L1 and L2 DTLBs
		MISALIGNED_ACCESSES = 0x47, // Misaligned Accesses
		MICROARCHITECTURAL_LATE_CANCEL_OF_AN_ACCESS = 0x48, // Microarchitectural Late Cancel of an Access
		MICROARCHITECTURAL_EARLY_CANCEL_OF_AN_ACCESS = 0x49, // Microarchitectural Early Cancel of an Access
		SCRUBBER_SINGLE_BIT_ECC_ERRORS = 0x4a, // Single-bit ECC Errors Recorded by Scrubber
		SCRUBBER_SINGLE_BIT_ECC_ERRORS__MASK__AMD64_FAM11H_SCRUBBER_SINGLE_BIT_ECC_ERRORS__SCRUBBER_ERROR = 0x1, // Scrubber error
		SCRUBBER_SINGLE_BIT_ECC_ERRORS__MASK__AMD64_FAM11H_SCRUBBER_SINGLE_BIT_ECC_ERRORS__PIGGYBACK_ERROR = 0x2, // Piggyback scrubber errors
		SCRUBBER_SINGLE_BIT_ECC_ERRORS__MASK__AMD64_FAM11H_SCRUBBER_SINGLE_BIT_ECC_ERRORS__ALL = 0x3, // All sub-events selected
		PREFETCH_INSTRUCTIONS_DISPATCHED = 0x4b, // Prefetch Instructions Dispatched
		PREFETCH_INSTRUCTIONS_DISPATCHED__MASK__AMD64_FAM11H_PREFETCH_INSTRUCTIONS_DISPATCHED__LOAD = 0x1, // Load (Prefetch
		PREFETCH_INSTRUCTIONS_DISPATCHED__MASK__AMD64_FAM11H_PREFETCH_INSTRUCTIONS_DISPATCHED__STORE = 0x2, // Store (PrefetchW)
		PREFETCH_INSTRUCTIONS_DISPATCHED__MASK__AMD64_FAM11H_PREFETCH_INSTRUCTIONS_DISPATCHED__NTA = 0x4, // NTA (PrefetchNTA)
		PREFETCH_INSTRUCTIONS_DISPATCHED__MASK__AMD64_FAM11H_PREFETCH_INSTRUCTIONS_DISPATCHED__ALL = 0x7, // All sub-events selected
		DCACHE_MISSES_BY_LOCKED_INSTRUCTIONS = 0x4c, // DCACHE Misses by Locked Instructions
		DCACHE_MISSES_BY_LOCKED_INSTRUCTIONS__MASK__AMD64_FAM11H_DCACHE_MISSES_BY_LOCKED_INSTRUCTIONS__DATA_CACHE_MISSES_BY_LOCKED_INSTRUCTIONS = 0x2, // Data cache misses by locked instructions
		DCACHE_MISSES_BY_LOCKED_INSTRUCTIONS__MASK__AMD64_FAM11H_DCACHE_MISSES_BY_LOCKED_INSTRUCTIONS__ALL = 0x2, // All sub-events selected
		MEMORY_REQUESTS = 0x65, // Memory Requests by Type
		MEMORY_REQUESTS__MASK__AMD64_FAM11H_MEMORY_REQUESTS__NON_CACHEABLE = 0x1, // Requests to non-cacheable (UC) memory
		MEMORY_REQUESTS__MASK__AMD64_FAM11H_MEMORY_REQUESTS__WRITE_COMBINING = 0x2, // Requests to write-combining (WC) memory or WC buffer flushes to WB memory
		MEMORY_REQUESTS__MASK__AMD64_FAM11H_MEMORY_REQUESTS__STREAMING_STORE = 0x80, // Streaming store (SS) requests
		MEMORY_REQUESTS__MASK__AMD64_FAM11H_MEMORY_REQUESTS__ALL = 0x83, // All sub-events selected
		DATA_PREFETCHES = 0x67, // Data Prefetcher
		DATA_PREFETCHES__MASK__AMD64_FAM11H_DATA_PREFETCHES__CANCELLED = 0x1, // Cancelled prefetches
		DATA_PREFETCHES__MASK__AMD64_FAM11H_DATA_PREFETCHES__ATTEMPTED = 0x2, // Prefetch attempts
		DATA_PREFETCHES__MASK__AMD64_FAM11H_DATA_PREFETCHES__ALL = 0x3, // All sub-events selected
		SYSTEM_READ_RESPONSES = 0x6c, // System Read Responses by Coherency State
		SYSTEM_READ_RESPONSES__MASK__AMD64_FAM11H_SYSTEM_READ_RESPONSES__EXCLUSIVE = 0x1, // Exclusive
		SYSTEM_READ_RESPONSES__MASK__AMD64_FAM11H_SYSTEM_READ_RESPONSES__MODIFIED = 0x2, // Modified
		SYSTEM_READ_RESPONSES__MASK__AMD64_FAM11H_SYSTEM_READ_RESPONSES__SHARED = 0x4, // Shared
		SYSTEM_READ_RESPONSES__MASK__AMD64_FAM11H_SYSTEM_READ_RESPONSES__DATA_ERROR = 0x10, // Data Error
		SYSTEM_READ_RESPONSES__MASK__AMD64_FAM11H_SYSTEM_READ_RESPONSES__ALL = 0x17, // All sub-events selected
		QUADWORDS_WRITTEN_TO_SYSTEM = 0x6d, // Quadwords Written to System
		QUADWORDS_WRITTEN_TO_SYSTEM__MASK__AMD64_FAM11H_QUADWORDS_WRITTEN_TO_SYSTEM__QUADWORD_WRITE_TRANSFER = 0x1, // Quadword write transfer
		QUADWORDS_WRITTEN_TO_SYSTEM__MASK__AMD64_FAM11H_QUADWORDS_WRITTEN_TO_SYSTEM__ALL = 0x1, // All sub-events selected
		CPU_CLK_UNHALTED = 0x76, // CPU Clocks not Halted
		REQUESTS_TO_L2 = 0x7d, // Requests to L2 Cache
		REQUESTS_TO_L2__MASK__AMD64_FAM11H_REQUESTS_TO_L2__INSTRUCTIONS = 0x1, // IC fill
		REQUESTS_TO_L2__MASK__AMD64_FAM11H_REQUESTS_TO_L2__DATA = 0x2, // DC fill
		REQUESTS_TO_L2__MASK__AMD64_FAM11H_REQUESTS_TO_L2__TLB_WALK = 0x4, // TLB fill (page table walks)
		REQUESTS_TO_L2__MASK__AMD64_FAM11H_REQUESTS_TO_L2__SNOOP = 0x8, // Tag snoop request
		REQUESTS_TO_L2__MASK__AMD64_FAM11H_REQUESTS_TO_L2__CANCELLED = 0x10, // Cancelled request
		REQUESTS_TO_L2__MASK__AMD64_FAM11H_REQUESTS_TO_L2__ALL = 0x1f, // All sub-events selected
		L2_CACHE_MISS = 0x7e, // L2 Cache Misses
		L2_CACHE_MISS__MASK__AMD64_FAM11H_L2_CACHE_MISS__INSTRUCTIONS = 0x1, // IC fill
		L2_CACHE_MISS__MASK__AMD64_FAM11H_L2_CACHE_MISS__DATA = 0x2, // DC fill (includes possible replays
		L2_CACHE_MISS__MASK__AMD64_FAM11H_L2_CACHE_MISS__TLB_WALK = 0x4, // TLB page table walk
		L2_CACHE_MISS__MASK__AMD64_FAM11H_L2_CACHE_MISS__ALL = 0x7, // All sub-events selected
		L2_FILL_WRITEBACK = 0x7f, // L2 Fill/Writeback
		L2_FILL_WRITEBACK__MASK__AMD64_FAM11H_L2_FILL_WRITEBACK__L2_FILLS = 0x1, // L2 fills (victims from L1 caches
		L2_FILL_WRITEBACK__MASK__AMD64_FAM11H_L2_FILL_WRITEBACK__L2_WRITEBACKS = 0x2, // L2 Writebacks to system.
		L2_FILL_WRITEBACK__MASK__AMD64_FAM11H_L2_FILL_WRITEBACK__ALL = 0x3, // All sub-events selected
		INSTRUCTION_CACHE_FETCHES = 0x80, // Instruction Cache Fetches
		INSTRUCTION_CACHE_MISSES = 0x81, // Instruction Cache Misses
		INSTRUCTION_CACHE_REFILLS_FROM_L2 = 0x82, // Instruction Cache Refills from L2
		INSTRUCTION_CACHE_REFILLS_FROM_SYSTEM = 0x83, // Instruction Cache Refills from System
		L1_ITLB_MISS_AND_L2_ITLB_HIT = 0x84, // L1 ITLB Miss and L2 ITLB Hit
		L1_ITLB_MISS_AND_L2_ITLB_MISS = 0x85, // L1 ITLB Miss and L2 ITLB Miss
		PIPELINE_RESTART_DUE_TO_INSTRUCTION_STREAM_PROBE = 0x86, // Pipeline Restart Due to Instruction Stream Probe
		INSTRUCTION_FETCH_STALL = 0x87, // Instruction Fetch Stall
		RETURN_STACK_HITS = 0x88, // Return Stack Hits
		RETURN_STACK_OVERFLOWS = 0x89, // Return Stack Overflows
		RETIRED_INSTRUCTIONS = 0xc0, // Retired Instructions
		RETIRED_UOPS = 0xc1, // Retired uops
		RETIRED_BRANCH_INSTRUCTIONS = 0xc2, // Retired Branch Instructions
		RETIRED_MISPREDICTED_BRANCH_INSTRUCTIONS = 0xc3, // Retired Mispredicted Branch Instructions
		RETIRED_TAKEN_BRANCH_INSTRUCTIONS = 0xc4, // Retired Taken Branch Instructions
		RETIRED_TAKEN_BRANCH_INSTRUCTIONS_MISPREDICTED = 0xc5, // Retired Taken Branch Instructions Mispredicted
		RETIRED_FAR_CONTROL_TRANSFERS = 0xc6, // Retired Far Control Transfers
		RETIRED_BRANCH_RESYNCS = 0xc7, // Retired Branch Resyncs
		RETIRED_NEAR_RETURNS = 0xc8, // Retired Near Returns
		RETIRED_NEAR_RETURNS_MISPREDICTED = 0xc9, // Retired Near Returns Mispredicted
		RETIRED_INDIRECT_BRANCHES_MISPREDICTED = 0xca, // Retired Indirect Branches Mispredicted
		RETIRED_MMX_AND_FP_INSTRUCTIONS = 0xcb, // Retired MMX/FP Instructions
		RETIRED_MMX_AND_FP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_MMX_AND_FP_INSTRUCTIONS__X87 = 0x1, // X87 instructions
		RETIRED_MMX_AND_FP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_MMX_AND_FP_INSTRUCTIONS__MMX_AND_3DNOW = 0x2, // MMX and 3DNow! instructions
		RETIRED_MMX_AND_FP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_MMX_AND_FP_INSTRUCTIONS__PACKED_SSE_AND_SSE2 = 0x4, // Packed SSE and SSE2 instructions
		RETIRED_MMX_AND_FP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_MMX_AND_FP_INSTRUCTIONS__SCALAR_SSE_AND_SSE2 = 0x8, // Scalar SSE and SSE2 instructions
		RETIRED_MMX_AND_FP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_MMX_AND_FP_INSTRUCTIONS__ALL = 0xf, // All sub-events selected
		RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS = 0xcc, // Retired Fastpath Double Op Instructions
		RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__POSITION_0 = 0x1, // With low op in position 0
		RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__POSITION_1 = 0x2, // With low op in position 1
		RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__POSITION_2 = 0x4, // With low op in position 2
		RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__MASK__AMD64_FAM11H_RETIRED_FASTPATH_DOUBLE_OP_INSTRUCTIONS__ALL = 0x7, // All sub-events selected
		INTERRUPTS_MASKED_CYCLES = 0xcd, // Interrupts-Masked Cycles
		INTERRUPTS_MASKED_CYCLES_WITH_INTERRUPT_PENDING = 0xce, // Interrupts-Masked Cycles with Interrupt Pending
		INTERRUPTS_TAKEN = 0xcf, // Interrupts Taken
		DECODER_EMPTY = 0xd0, // Decoder Empty
		DISPATCH_STALLS = 0xd1, // Dispatch Stalls
		DISPATCH_STALL_FOR_BRANCH_ABORT = 0xd2, // Dispatch Stall for Branch Abort to Retire
		DISPATCH_STALL_FOR_SERIALIZATION = 0xd3, // Dispatch Stall for Serialization
		DISPATCH_STALL_FOR_SEGMENT_LOAD = 0xd4, // Dispatch Stall for Segment Load
		DISPATCH_STALL_FOR_REORDER_BUFFER_FULL = 0xd5, // Dispatch Stall for Reorder Buffer Full
		DISPATCH_STALL_FOR_RESERVATION_STATION_FULL = 0xd6, // Dispatch Stall for Reservation Station Full
		DISPATCH_STALL_FOR_FPU_FULL = 0xd7, // Dispatch Stall for FPU Full
		DISPATCH_STALL_FOR_LS_FULL = 0xd8, // Dispatch Stall for LS Full
		DISPATCH_STALL_WAITING_FOR_ALL_QUIET = 0xd9, // Dispatch Stall Waiting for All Quiet
		DISPATCH_STALL_FOR_FAR_TRANSFER_OR_RSYNC = 0xda, // Dispatch Stall for Far Transfer or Resync to Retire
		FPU_EXCEPTIONS = 0xdb, // FPU Exceptions
		FPU_EXCEPTIONS__MASK__AMD64_FAM11H_FPU_EXCEPTIONS__X87_RECLASS_MICROFAULTS = 0x1, // X87 reclass microfaults
		FPU_EXCEPTIONS__MASK__AMD64_FAM11H_FPU_EXCEPTIONS__SSE_RETYPE_MICROFAULTS = 0x2, // SSE retype microfaults
		FPU_EXCEPTIONS__MASK__AMD64_FAM11H_FPU_EXCEPTIONS__SSE_RECLASS_MICROFAULTS = 0x4, // SSE reclass microfaults
		FPU_EXCEPTIONS__MASK__AMD64_FAM11H_FPU_EXCEPTIONS__SSE_AND_X87_MICROTRAPS = 0x8, // SSE and x87 microtraps
		FPU_EXCEPTIONS__MASK__AMD64_FAM11H_FPU_EXCEPTIONS__ALL = 0xf, // All sub-events selected
		DR0_BREAKPOINT_MATCHES = 0xdc, // DR0 Breakpoint Matches
		DR1_BREAKPOINT_MATCHES = 0xdd, // DR1 Breakpoint Matches
		DR2_BREAKPOINT_MATCHES = 0xde, // DR2 Breakpoint Matches
		DR3_BREAKPOINT_MATCHES = 0xdf, // DR3 Breakpoint Matches
		DRAM_ACCESSES = 0xe0, // DRAM Accesses
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__DCT0_PAGE_HIT = 0x1, // DCT0 Page hit
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__DCT0_PAGE_MISS = 0x2, // DCT0 Page Miss
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__DCT0_PAGE_CONFLICT = 0x4, // DCT0 Page Conflict
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__DCT1_PAGE_HIT = 0x8, // DCT1 Page hit
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__DCT1_PAGE_MISS = 0x10, // DCT1 Page Miss
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__DCT1_PAGE_CONFLICT = 0x20, // DCT1 Page Conflict
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__WRITE_REQUEST = 0x40, // Write request.
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__READ_REQUEST = 0x80, // Read request.
		DRAM_ACCESSES__MASK__AMD64_FAM11H_DRAM_ACCESSES__ALL = 0xff, // All sub-events selected
		DRAM_CONTROLLER_PAGE_TABLE_EVENTS = 0xe1, // DRAM Controller Page Table Events
		DRAM_CONTROLLER_PAGE_TABLE_EVENTS__MASK__AMD64_FAM11H_DRAM_CONTROLLER_PAGE_TABLE_EVENTS__DCT_PAGE_TABLE_OVERFLOW = 0x1, // DCT Page Table Overflow
		DRAM_CONTROLLER_PAGE_TABLE_EVENTS__MASK__AMD64_FAM11H_DRAM_CONTROLLER_PAGE_TABLE_EVENTS__STALE_TABLE_ENTRY_HITS = 0x2, // Number of stale table entry hits. (hit on a page closed too soon).
		DRAM_CONTROLLER_PAGE_TABLE_EVENTS__MASK__AMD64_FAM11H_DRAM_CONTROLLER_PAGE_TABLE_EVENTS__PAGE_TABLE_IDLE_CYCLE_LIMIT_INCREMENTED = 0x4, // Page table idle cycle limit incremented.
		DRAM_CONTROLLER_PAGE_TABLE_EVENTS__MASK__AMD64_FAM11H_DRAM_CONTROLLER_PAGE_TABLE_EVENTS__PAGE_TABLE_IDLE_CYCLE_LIMIT_DECREMENTED = 0x8, // Page table idle cycle limit decremented.
		DRAM_CONTROLLER_PAGE_TABLE_EVENTS__MASK__AMD64_FAM11H_DRAM_CONTROLLER_PAGE_TABLE_EVENTS__ALL = 0xf, // All sub-events selected
		MEMORY_CONTROLLER_TURNAROUNDS = 0xe3, // Memory Controller Turnarounds
		MEMORY_CONTROLLER_TURNAROUNDS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_TURNAROUNDS__DCT0_READ_TO_WRITE = 0x1, // DCT0 read-to-write turnaround.
		MEMORY_CONTROLLER_TURNAROUNDS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_TURNAROUNDS__DCT0_WRITE_TO_READ = 0x2, // DCT0 write-to-read turnaround
		MEMORY_CONTROLLER_TURNAROUNDS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_TURNAROUNDS__DCT0_DIMM = 0x4, // DCT0 DIMM (chip select) turnaround
		MEMORY_CONTROLLER_TURNAROUNDS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_TURNAROUNDS__DCT1_READ_TO_WRITE = 0x8, // DCT1 read-to-write turnaround.
		MEMORY_CONTROLLER_TURNAROUNDS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_TURNAROUNDS__DCT1_WRITE_TO_READ = 0x10, // DCT1 write-to-read turnaround
		MEMORY_CONTROLLER_TURNAROUNDS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_TURNAROUNDS__DCT1_DIMM = 0x20, // DCT1 DIMM (chip select) turnaround
		MEMORY_CONTROLLER_TURNAROUNDS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_TURNAROUNDS__ALL = 0x3f, // All sub-events selected
		MEMORY_CONTROLLER_RBD_QUEUE = 0xe4, // Memory Controller RBD Queue Events
		MEMORY_CONTROLLER_RBD_QUEUE__MASK__AMD64_FAM11H_MEMORY_RBD_QUEUE__COUNTER_REACHED = 0x4, // F2x[1
		MEMORY_CONTROLLER_RBD_QUEUE__MASK__AMD64_FAM11H_MEMORY_RBD_QUEUE__ALL = 0x4, // All sub-events selected
		THERMAL_STATUS = 0xe8, // Thermal Status
		THERMAL_STATUS__MASK__AMD64_FAM11H_THERMAL_STATUS__MEMHOT_L_ASSERTIONS = 0x1, // Number of clocks MEMHOT_L is asserted.
		THERMAL_STATUS__MASK__AMD64_FAM11H_THERMAL_STATUS__HTC_TRANSITIONS = 0x4, // Number of times the HTC transitions from inactive to active.
		THERMAL_STATUS__MASK__AMD64_FAM11H_THERMAL_STATUS__CLOCKS_HTC_P_STATE_INACTIVE = 0x20, // Number of clocks HTC P-state is inactive.
		THERMAL_STATUS__MASK__AMD64_FAM11H_THERMAL_STATUS__CLOCKS_HTC_P_STATE_ACTIVE = 0x40, // Number of clocks HTC P-state is active
		THERMAL_STATUS__MASK__AMD64_FAM11H_THERMAL_STATUS__PROCHOT_L_ASSERTIONS = 0x80, // PROCHOT_L asserted by an external source and the assertion causes a P-state change.
		THERMAL_STATUS__MASK__AMD64_FAM11H_THERMAL_STATUS__ALL = 0xe5, // All sub-events selected
		CPU_IO_REQUESTS_TO_MEMORY_IO = 0xe9, // CPU/IO Requests to Memory/IO
		CPU_IO_REQUESTS_TO_MEMORY_IO__MASK__AMD64_FAM11H_CPU_IO_REQUESTS_TO_MEMORY_IO__I_O_TO_I_O = 0xa1, // IO to IO
		CPU_IO_REQUESTS_TO_MEMORY_IO__MASK__AMD64_FAM11H_CPU_IO_REQUESTS_TO_MEMORY_IO__I_O_TO_MEM = 0xa2, // IO to Mem
		CPU_IO_REQUESTS_TO_MEMORY_IO__MASK__AMD64_FAM11H_CPU_IO_REQUESTS_TO_MEMORY_IO__CPU_TO_I_O = 0xa4, // CPU to IO
		CPU_IO_REQUESTS_TO_MEMORY_IO__MASK__AMD64_FAM11H_CPU_IO_REQUESTS_TO_MEMORY_IO__CPU_TO_MEM = 0xa8, // CPU to Mem
		CPU_IO_REQUESTS_TO_MEMORY_IO__MASK__AMD64_FAM11H_CPU_IO_REQUESTS_TO_MEMORY_IO__ALL = 0xaf, // All sub-events selected
		CACHE_BLOCK = 0xea, // Cache Block Commands
		CACHE_BLOCK__MASK__AMD64_FAM11H_CACHE_BLOCK__VICTIM_WRITEBACK = 0x1, // Victim Block (Writeback)
		CACHE_BLOCK__MASK__AMD64_FAM11H_CACHE_BLOCK__DCACHE_LOAD_MISS = 0x4, // Read Block (Dcache load miss refill)
		CACHE_BLOCK__MASK__AMD64_FAM11H_CACHE_BLOCK__SHARED_ICACHE_REFILL = 0x8, // Read Block Shared (Icache refill)
		CACHE_BLOCK__MASK__AMD64_FAM11H_CACHE_BLOCK__READ_BLOCK_MODIFIED = 0x10, // Read Block Modified (Dcache store miss refill)
		CACHE_BLOCK__MASK__AMD64_FAM11H_CACHE_BLOCK__READ_TO_DIRTY = 0x20, // Change-to-Dirty (first store to clean block already in cache)
		CACHE_BLOCK__MASK__AMD64_FAM11H_CACHE_BLOCK__ALL = 0x3d, // All sub-events selected
		SIZED_COMMANDS = 0xeb, // Sized Commands
		SIZED_COMMANDS__MASK__AMD64_FAM11H_SIZED_COMMANDS__NON_POSTED_WRITE_BYTE = 0x1, // Non-Posted SzWr Byte (1-32 bytes) Legacy or mapped IO
		SIZED_COMMANDS__MASK__AMD64_FAM11H_SIZED_COMMANDS__NON_POSTED_WRITE_DWORD = 0x2, // Non-Posted SzWr DW (1-16 dwords) Legacy or mapped IO
		SIZED_COMMANDS__MASK__AMD64_FAM11H_SIZED_COMMANDS__POSTED_WRITE_BYTE = 0x4, // Posted SzWr Byte (1-32 bytes) Subcache-line DMA writes
		SIZED_COMMANDS__MASK__AMD64_FAM11H_SIZED_COMMANDS__POSTED_WRITE_DWORD = 0x8, // Posted SzWr DW (1-16 dwords) Block-oriented DMA writes
		SIZED_COMMANDS__MASK__AMD64_FAM11H_SIZED_COMMANDS__READ_BYTE_4_BYTES = 0x10, // SzRd Byte (4 bytes) Legacy or mapped IO
		SIZED_COMMANDS__MASK__AMD64_FAM11H_SIZED_COMMANDS__READ_DWORD_1_16_DWORDS = 0x20, // SzRd DW (1-16 dwords) Block-oriented DMA reads
		SIZED_COMMANDS__MASK__AMD64_FAM11H_SIZED_COMMANDS__ALL = 0x3f, // All sub-events selected
		PROBE = 0xec, // Probe Responses and Upstream Requests
		PROBE__MASK__AMD64_FAM11H_PROBE__MISS = 0x1, // Probe miss
		PROBE__MASK__AMD64_FAM11H_PROBE__HIT_CLEAN = 0x2, // Probe hit clean
		PROBE__MASK__AMD64_FAM11H_PROBE__HIT_DIRTY_NO_MEMORY_CANCEL = 0x4, // Probe hit dirty without memory cancel (probed by Sized Write or Change2Dirty)
		PROBE__MASK__AMD64_FAM11H_PROBE__HIT_DIRTY_WITH_MEMORY_CANCEL = 0x8, // Probe hit dirty with memory cancel (probed by DMA read or cache refill request)
		PROBE__MASK__AMD64_FAM11H_PROBE__UPSTREAM_DISPLAY_REFRESH_READS = 0x10, // Upstream display refresh/ISOC reads.
		PROBE__MASK__AMD64_FAM11H_PROBE__UPSTREAM_NON_DISPLAY_REFRESH_READS = 0x20, // Upstream non-display refresh reads.
		PROBE__MASK__AMD64_FAM11H_PROBE__UPSTREAM_ISOC_WRITES = 0x40, // Upstream ISOC writes.
		PROBE__MASK__AMD64_FAM11H_PROBE__UPSTREAM_NON_ISOC_WRITES = 0x80, // Upstream non-ISOC writes.
		PROBE__MASK__AMD64_FAM11H_PROBE__ALL = 0xff, // All sub-events selected
		DEV = 0xee, // DEV Events
		DEV__MASK__AMD64_FAM11H_DEV__DEV_HIT = 0x10, // DEV hit
		DEV__MASK__AMD64_FAM11H_DEV__DEV_MISS = 0x20, // DEV miss
		DEV__MASK__AMD64_FAM11H_DEV__DEV_ERROR = 0x40, // DEV error
		DEV__MASK__AMD64_FAM11H_DEV__ALL = 0x70, // All sub-events selected
		HYPERTRANSPORT_LINK0 = 0xf6, // HyperTransport Link 0 Transmit Bandwidth
		HYPERTRANSPORT_LINK0__MASK__AMD64_FAM11H_HYPERTRANSPORT_LINK0__COMMAND_DWORD_SENT = 0x1, // Command DWORD sent
		HYPERTRANSPORT_LINK0__MASK__AMD64_FAM11H_HYPERTRANSPORT_LINK0__ADDRESS_DWORD_SENT = 0x2, // Address DWORD sent
		HYPERTRANSPORT_LINK0__MASK__AMD64_FAM11H_HYPERTRANSPORT_LINK0__DATA_DWORD_SENT = 0x4, // Data DWORD sent
		HYPERTRANSPORT_LINK0__MASK__AMD64_FAM11H_HYPERTRANSPORT_LINK0__BUFFER_RELEASE_DWORD_SENT = 0x8, // Buffer release DWORD sent
		HYPERTRANSPORT_LINK0__MASK__AMD64_FAM11H_HYPERTRANSPORT_LINK0__NOP_DWORD_SENT = 0x10, // Nop DW sent (idle)
		HYPERTRANSPORT_LINK0__MASK__AMD64_FAM11H_HYPERTRANSPORT_LINK0__PER_PACKET_CRC_SENT = 0x20, // Per packet CRC sent
		HYPERTRANSPORT_LINK0__MASK__AMD64_FAM11H_HYPERTRANSPORT_LINK0__ALL = 0x3f, // All sub-events selected
		MEMORY_CONTROLLER_REQUESTS = 0x1f0, // Memory Controller Requests
		MEMORY_CONTROLLER_REQUESTS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_REQUESTS__32_BYTES_WRITES = 0x8, // 32 Bytes Sized Writes
		MEMORY_CONTROLLER_REQUESTS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_REQUESTS__64_BYTES_WRITES = 0x10, // 64 Bytes Sized Writes
		MEMORY_CONTROLLER_REQUESTS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_REQUESTS__32_BYTES_READS = 0x20, // 32 Bytes Sized Reads
		MEMORY_CONTROLLER_REQUESTS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_REQUESTS__64_BYTES_READS = 0x40, // 64 Byte Sized Reads
		MEMORY_CONTROLLER_REQUESTS__MASK__AMD64_FAM11H_MEMORY_CONTROLLER_REQUESTS__ALL = 0x78, // All sub-events selected
		SIDEBAND_SIGNALS = 0x1e9, // Sideband Signals and Special Cycles
		SIDEBAND_SIGNALS__MASK__AMD64_FAM11H_SIDEBAND_SIGNALS__HALT = 0x1, // HALT
		SIDEBAND_SIGNALS__MASK__AMD64_FAM11H_SIDEBAND_SIGNALS__STOPGRANT = 0x2, // STOPGRANT
		SIDEBAND_SIGNALS__MASK__AMD64_FAM11H_SIDEBAND_SIGNALS__SHUTDOWN = 0x4, // SHUTDOWN
		SIDEBAND_SIGNALS__MASK__AMD64_FAM11H_SIDEBAND_SIGNALS__WBINVD = 0x8, // WBINVD
		SIDEBAND_SIGNALS__MASK__AMD64_FAM11H_SIDEBAND_SIGNALS__INVD = 0x10, // INVD
		SIDEBAND_SIGNALS__MASK__AMD64_FAM11H_SIDEBAND_SIGNALS__ALL = 0x1f, // All sub-events selected
		INTERRUPT_EVENTS = 0x1ea, // Interrupt Events
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__FIXED_AND_LPA = 0x1, // Fixed and LPA
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__LPA = 0x2, // LPA
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__SMI = 0x4, // SMI
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__NMI = 0x8, // NMI
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__INIT = 0x10, // INIT
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__STARTUP = 0x20, // STARTUP
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__INT = 0x40, // INT
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__EOI = 0x80, // EOI
		INTERRUPT_EVENTS__MASK__AMD64_FAM11H_INTERRUPT_EVENTS__ALL = 0xff, // All sub-events selected
		
	};
};