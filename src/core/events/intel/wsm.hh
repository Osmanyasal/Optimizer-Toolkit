#include <cstdint>

namespace optkit_intel{
	enum class wsm : uint64_t {
		UNHALTED_CORE_CYCLES = 0x3c, // Count core clock cycles whenever the clock signal on the specific core is running (not halted).
		INSTRUCTION_RETIRED = 0xc0, // Count the number of instructions at retirement.
		INSTRUCTIONS_RETIRED = 0xc0, // This is an alias for INSTRUCTION_RETIRED
		UNHALTED_REFERENCE_CYCLES = 0x0300, // Unhalted reference cycles
		LLC_REFERENCES = 0x4f2e, // Count each request originating from the core to reference a cache line in the last level cache. The count may include speculation
		LAST_LEVEL_CACHE_REFERENCES = 0x4f2e, // This is an alias for L3_LAT_CACHE:REFERENCE
		LLC_MISSES = 0x412e, // Count each cache miss condition for references to the last level cache. The event count may include speculation
		LAST_LEVEL_CACHE_MISSES = 0x412e, // This is an alias for L3_LAT_CACHE:MISS
		BRANCH_INSTRUCTIONS_RETIRED = 0x4c4, // Count branch instructions at retirement. Specifically
		UOPS_DECODED = 0xd1, // Micro-ops decoded
		UOPS_DECODED_MASK_ESP_FOLDING = 0x400, // Stack pointer instructions decoded
		UOPS_DECODED_MASK_ESP_SYNC = 0x800, // Stack pointer sync operations
		UOPS_DECODED_MASK_MS = 0x200, // Counts the number of uops decoded by the Microcode Sequencer (MS). The MS delivers uops when the instruction is more than 4 uops long or a microcode assist is occurring.
		UOPS_DECODED_MASK_MS_CYCLES_ACTIVE = 0x200 | (0x1 << INTEL_X86_CMASK_BIT), // Uops decoded by Microcode Sequencer
		UOPS_DECODED_MASK_STALL_CYCLES = 0x100 | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles no Uops are decoded
		L1D_CACHE_LOCK_FB_HIT = 0x152, // L1D cacheable load lock speculated or retired accepted into the fill buffer
		BPU_CLEARS = 0xe8, // Branch Prediction Unit clears
		BPU_CLEARS_MASK_EARLY = 0x100, // Early Branch Prediction Unit clears
		BPU_CLEARS_MASK_LATE = 0x200, // Late Branch Prediction Unit clears
		UOPS_RETIRED = 0xc2, // Cycles Uops are being retired (Precise Event)
		UOPS_RETIRED_MASK_ANY = 0x100, // Uops retired (Precise Event)
		UOPS_RETIRED_MASK_MACRO_FUSED = 0x400, // Macro-fused Uops retired (Precise Event)
		UOPS_RETIRED_MASK_RETIRE_SLOTS = 0x200, // Retirement slots used (Precise Event)
		UOPS_RETIRED_MASK_STALL_CYCLES = 0x100 | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles Uops are not retiring (Precise Event)
		UOPS_RETIRED_MASK_TOTAL_CYCLES = 0x100 | INTEL_X86_MOD_INV | (0x10 << INTEL_X86_CMASK_BIT), // Total cycles using precise uop retired event (Precise Event)
		UOPS_RETIRED_MASK_ACTIVE_CYCLES = 0x100 | (0x1 << INTEL_X86_CMASK_BIT), // Alias for TOTAL_CYCLES (Precise Event)
		BR_MISP_RETIRED = 0xc5, // Mispredicted retired branches (Precise Event)
		BR_MISP_RETIRED_MASK_ALL_BRANCHES = 0x0, // Mispredicted retired branch instructions (Precise Event)
		BR_MISP_RETIRED_MASK_NEAR_CALL = 0x200, // Mispredicted near retired calls (Precise Event)
		BR_MISP_RETIRED_MASK_CONDITIONAL = 0x100, // Mispredicted conditional branches retired (Precise Event)
		EPT = 0x4f, // Extended Page Table
		EPT_MASK_WALK_CYCLES = 0x1000, // Extended Page Table walk cycles
		UOPS_EXECUTED = 0xb1, // Micro-ops executed
		UOPS_EXECUTED_MASK_PORT0 = 0x100, // Uops executed on port 0 (integer arithmetic
		UOPS_EXECUTED_MASK_PORT1 = 0x200, // Uops executed on port 1 (integer arithmetic
		UOPS_EXECUTED_MASK_PORT2_CORE = 0x400 | INTEL_X86_MOD_ANY, // Uops executed on port 2 on any thread (load uops) (core count only)
		UOPS_EXECUTED_MASK_PORT3_CORE = 0x800 | INTEL_X86_MOD_ANY, // Uops executed on port 3 on any thread (store uops) (core count only)
		UOPS_EXECUTED_MASK_PORT4_CORE = 0x1000 | INTEL_X86_MOD_ANY, // Uops executed on port 4 on any thread (handle store values for stores on port 3) (core count only)
		UOPS_EXECUTED_MASK_PORT5 = 0x2000, // Uops executed on port 5
		UOPS_EXECUTED_MASK_PORT015 = 0x4000, // Uops issued on ports 0
		UOPS_EXECUTED_MASK_PORT234_CORE = 0x8000 | INTEL_X86_MOD_ANY, // Uops issued on ports 2
		UOPS_EXECUTED_MASK_PORT015_STALL_CYCLES = 0x4000 | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles no Uops issued on ports 0
		UOPS_EXECUTED_MASK_CORE_ACTIVE_CYCLES_NO_PORT5 = 0x1f00 | INTEL_X86_MOD_ANY | (0x1 << INTEL_X86_CMASK_BIT), // Cycles in which uops are executed only on port0-4 on any thread (core count only)
		UOPS_EXECUTED_MASK_CORE_ACTIVE_CYCLES = 0x3f00 | INTEL_X86_MOD_ANY | (0x1 << INTEL_X86_CMASK_BIT), // Cycles in which uops are executed on any port any thread (core count only)
		UOPS_EXECUTED_MASK_CORE_STALL_CYCLES = 0x3f00 | INTEL_X86_MOD_ANY | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles in which no uops are executed on any port any thread (core count only)
		UOPS_EXECUTED_MASK_CORE_STALL_CYCLES_NO_PORT5 = 0x1f00 | INTEL_X86_MOD_ANY | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles in which no uops are executed on any port0-4 on any thread (core count only)
		UOPS_EXECUTED_MASK_CORE_STALL_COUNT = 0x3f00 | INTEL_X86_MOD_EDGE | INTEL_X86_MOD_ANY | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Number of transitions from stalled to uops to execute on any port any thread (core count only)
		UOPS_EXECUTED_MASK_CORE_STALL_COUNT_NO_PORT5 = 0x1f00 | INTEL_X86_MOD_EDGE | INTEL_X86_MOD_ANY | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Number of transitions from stalled to uops to execute on ports 0-4 on any thread (core count only)
		IO_TRANSACTIONS = 0x16c, // I/O transactions
		ES_REG_RENAMES = 0x1d5, // ES segment renames
		INST_RETIRED = 0xc0, // Instructions retired (Precise Event)
		INST_RETIRED_MASK_ANY_P = 0x100, // Instructions Retired (Precise Event)
		INST_RETIRED_MASK_ANY = 0x100, // Instructions Retired (Precise Event)
		INST_RETIRED_MASK_X87 = 0x200, // Retired floating-point operations (Precise Event)
		INST_RETIRED_MASK_MMX = 0x400, // Retired MMX instructions (Precise Event)
		INST_RETIRED_MASK_TOTAL_CYCLES = 0x100 | INTEL_X86_MOD_INV | (0x10 << INTEL_X86_CMASK_BIT), // Total cycles (Precise Event)
		ILD_STALL = 0x87, // Instruction Length Decoder stalls
		ILD_STALL_MASK_ANY = 0xf00, // Any Instruction Length Decoder stall cycles
		ILD_STALL_MASK_IQ_FULL = 0x400, // Instruction Queue full stall cycles
		ILD_STALL_MASK_LCP = 0x100, // Length Change Prefix stall cycles
		ILD_STALL_MASK_MRU = 0x200, // Stall cycles due to BPU MRU bypass
		ILD_STALL_MASK_REGEN = 0x800, // Regen stall cycles
		DTLB_LOAD_MISSES = 0x8, // DTLB load misses
		DTLB_LOAD_MISSES_MASK_ANY = 0x100, // DTLB load misses
		DTLB_LOAD_MISSES_MASK_PDE_MISS = 0x2000, // DTLB load miss caused by low part of address
		DTLB_LOAD_MISSES_MASK_STLB_HIT = 0x1000, // DTLB second level hit
		DTLB_LOAD_MISSES_MASK_WALK_COMPLETED = 0x200, // DTLB load miss page walks complete
		DTLB_LOAD_MISSES_MASK_WALK_CYCLES = 0x400, // DTLB load miss page walk cycles
		DTLB_LOAD_MISSES_MASK_LARGE_WALK_COMPLETED = 0x8000, // DTLB load miss large page walk cycles
		L2_LINES_IN = 0xf1, // L2 lines allocated
		L2_LINES_IN_MASK_ANY = 0x700, // L2 lines allocated
		L2_LINES_IN_MASK_E_STATE = 0x400, // L2 lines allocated in the E state
		L2_LINES_IN_MASK_S_STATE = 0x200, // L2 lines allocated in the S state
		SSEX_UOPS_RETIRED = 0xc7, // SIMD micro-ops retired (Precise Event)
		SSEX_UOPS_RETIRED_MASK_PACKED_DOUBLE = 0x400, // SIMD Packed-Double Uops retired (Precise Event)
		SSEX_UOPS_RETIRED_MASK_PACKED_SINGLE = 0x100, // SIMD Packed-Single Uops retired (Precise Event)
		SSEX_UOPS_RETIRED_MASK_SCALAR_DOUBLE = 0x800, // SIMD Scalar-Double Uops retired (Precise Event)
		SSEX_UOPS_RETIRED_MASK_SCALAR_SINGLE = 0x200, // SIMD Scalar-Single Uops retired (Precise Event)
		SSEX_UOPS_RETIRED_MASK_VECTOR_INTEGER = 0x1000, // SIMD Vector Integer Uops retired (Precise Event)
		STORE_BLOCKS = 0x6, // Load delayed by block code
		STORE_BLOCKS_MASK_AT_RET = 0x400, // Loads delayed with at-Retirement block code
		STORE_BLOCKS_MASK_L1D_BLOCK = 0x800, // Cacheable loads delayed with L1D block code
		FP_MMX_TRANS = 0xcc, // Floating Point to and from MMX transitions
		FP_MMX_TRANS_MASK_ANY = 0x300, // All Floating Point to and from MMX transitions
		FP_MMX_TRANS_MASK_TO_FP = 0x100, // Transitions from MMX to Floating Point instructions
		FP_MMX_TRANS_MASK_TO_MMX = 0x200, // Transitions from Floating Point to MMX instructions
		CACHE_LOCK_CYCLES = 0x63, // Cache locked
		CACHE_LOCK_CYCLES_MASK_L1D = 0x200, // Cycles L1D locked
		CACHE_LOCK_CYCLES_MASK_L1D_L2 = 0x100, // Cycles L1D and L2 locked
		OFFCORE_REQUESTS_SQ_FULL = 0x1b2, // Offcore requests blocked due to Super Queue full
		LONGEST_LAT_CACHE = 0x2e, // Last level cache accesses
		LONGEST_LAT_CACHE_MASK_MISS = 0x4100, // Last level cache miss
		LONGEST_LAT_CACHE_MASK_REFERENCE = 0x4f00, // Last level cache reference
		L3_LAT_CACHE = 0x2e, // Last level cache accesses
		L3_LAT_CACHE_MASK_MISS = 0x4100, // Last level cache miss
		L3_LAT_CACHE_MASK_REFERENCE = 0x4f00, // Last level cache reference
		SIMD_INT_64 = 0xfd, // SIMD 64-bit integer operations
		SIMD_INT_64_MASK_PACK = 0x400, // SIMD integer 64 bit pack operations
		SIMD_INT_64_MASK_PACKED_ARITH = 0x2000, // SIMD integer 64 bit arithmetic operations
		SIMD_INT_64_MASK_PACKED_LOGICAL = 0x1000, // SIMD integer 64 bit logical operations
		SIMD_INT_64_MASK_PACKED_MPY = 0x100, // SIMD integer 64 bit packed multiply operations
		SIMD_INT_64_MASK_PACKED_SHIFT = 0x200, // SIMD integer 64 bit shift operations
		SIMD_INT_64_MASK_SHUFFLE_MOVE = 0x4000, // SIMD integer 64 bit shuffle/move operations
		SIMD_INT_64_MASK_UNPACK = 0x800, // SIMD integer 64 bit unpack operations
		BR_INST_DECODED = 0x1e0, // Branch instructions decoded
		BR_MISP_EXEC = 0x89, // Mispredicted branches executed
		BR_MISP_EXEC_MASK_ANY = 0x7f00, // Mispredicted branches executed
		BR_MISP_EXEC_MASK_COND = 0x100, // Mispredicted conditional branches executed
		BR_MISP_EXEC_MASK_DIRECT = 0x200, // Mispredicted unconditional branches executed
		BR_MISP_EXEC_MASK_DIRECT_NEAR_CALL = 0x1000, // Mispredicted non call branches executed
		BR_MISP_EXEC_MASK_INDIRECT_NEAR_CALL = 0x2000, // Mispredicted indirect call branches executed
		BR_MISP_EXEC_MASK_INDIRECT_NON_CALL = 0x400, // Mispredicted indirect non call branches executed
		BR_MISP_EXEC_MASK_NEAR_CALLS = 0x3000, // Mispredicted call branches executed
		BR_MISP_EXEC_MASK_NON_CALLS = 0x700, // Mispredicted non call branches executed
		BR_MISP_EXEC_MASK_RETURN_NEAR = 0x800, // Mispredicted return branches executed
		BR_MISP_EXEC_MASK_TAKEN = 0x4000, // Mispredicted taken branches executed
		SQ_FULL_STALL_CYCLES = 0x1f6, // Super Queue full stall cycles
		BACLEAR = 0xe6, // Branch address calculator clears
		BACLEAR_MASK_BAD_TARGET = 0x200, // BACLEAR asserted with bad target address
		BACLEAR_MASK_CLEAR = 0x100, // BACLEAR asserted
		DTLB_MISSES = 0x49, // Data TLB misses
		DTLB_MISSES_MASK_ANY = 0x100, // DTLB misses
		DTLB_MISSES_MASK_LARGE_WALK_COMPLETED = 0x8000, // DTLB miss large page walks
		DTLB_MISSES_MASK_STLB_HIT = 0x1000, // DTLB first level misses but second level hit
		DTLB_MISSES_MASK_WALK_COMPLETED = 0x200, // DTLB miss page walks
		DTLB_MISSES_MASK_WALK_CYCLES = 0x400, // DTLB miss page walk cycles
		DTLB_MISSES_MASK_PDE_MISS = 0x2000, // DTLB miss caused by low part of address
		MEM_INST_RETIRED = 0xb, // Memory instructions retired (Precise Event)
		MEM_INST_RETIRED_MASK_LATENCY_ABOVE_THRESHOLD = 0x1000, // Memory instructions retired above programmed clocks
		MEM_INST_RETIRED_MASK_LOADS = 0x100, // Instructions retired which contains a load (Precise Event)
		MEM_INST_RETIRED_MASK_STORES = 0x200, // Instructions retired which contains a store (Precise Event)
		UOPS_ISSUED = 0xe, // Uops issued
		UOPS_ISSUED_MASK_ANY = 0x100, // Uops issued
		UOPS_ISSUED_MASK_STALL_CYCLES = 0x100 | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles stalled no issued uops
		UOPS_ISSUED_MASK_FUSED = 0x200, // Fused Uops issued
		UOPS_ISSUED_MASK_CYCLES_ALL_THREADS = 0x100 | INTEL_X86_MOD_ANY | (0x1 << INTEL_X86_CMASK_BIT), // Cycles uops issued on either threads (core count)
		UOPS_ISSUED_MASK_CORE_STALL_CYCLES = 0x100 | INTEL_X86_MOD_ANY | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles no uops issued on any threads (core count)
		L2_RQSTS = 0x24, // L2 requests
		L2_RQSTS_MASK_IFETCH_HIT = 0x1000, // L2 instruction fetch hits
		L2_RQSTS_MASK_IFETCH_MISS = 0x2000, // L2 instruction fetch misses
		L2_RQSTS_MASK_IFETCHES = 0x3000, // L2 instruction fetches
		L2_RQSTS_MASK_LD_HIT = 0x100, // L2 load hits
		L2_RQSTS_MASK_LD_MISS = 0x200, // L2 load misses
		L2_RQSTS_MASK_LOADS = 0x300, // L2 requests
		L2_RQSTS_MASK_MISS = 0xaa00, // All L2 misses
		L2_RQSTS_MASK_PREFETCH_HIT = 0x4000, // L2 prefetch hits
		L2_RQSTS_MASK_PREFETCH_MISS = 0x8000, // L2 prefetch misses
		L2_RQSTS_MASK_PREFETCHES = 0xc000, // All L2 prefetches
		L2_RQSTS_MASK_REFERENCES = 0xff00, // All L2 requests
		L2_RQSTS_MASK_RFO_HIT = 0x400, // L2 RFO hits
		L2_RQSTS_MASK_RFO_MISS = 0x800, // L2 RFO misses
		L2_RQSTS_MASK_RFOS = 0xc00, // L2 RFO requests
		TWO_UOP_INSTS_DECODED = 0x119, // Two Uop instructions decoded
		LOAD_DISPATCH = 0x13, // Loads dispatched
		LOAD_DISPATCH_MASK_ANY = 0x700, // All loads dispatched
		LOAD_DISPATCH_MASK_RS = 0x100, // Number of loads dispatched from the Reservation Station (RS) that bypass the Memory Order Buffer
		LOAD_DISPATCH_MASK_RS_DELAYED = 0x200, // Number of delayed RS dispatches at the stage latch
		LOAD_DISPATCH_MASK_MOB = 0x400, // Number of loads dispatched from Reservation Station (RS)
		BACLEAR_FORCE_IQ = 0x1a7, // BACLEAR forced by Instruction queue
		SNOOPQ_REQUESTS = 0xb4, // Snoopq requests
		SNOOPQ_REQUESTS_MASK_CODE = 0x400, // Snoop code requests
		SNOOPQ_REQUESTS_MASK_DATA = 0x100, // Snoop data requests
		SNOOPQ_REQUESTS_MASK_INVALIDATE = 0x200, // Snoop invalidate requests
		OFFCORE_REQUESTS = 0xb0, // Offcore requests
		OFFCORE_REQUESTS_MASK_ANY = 0x8000, // All offcore requests
		OFFCORE_REQUESTS_MASK_ANY_READ = 0x800, // Offcore read requests
		OFFCORE_REQUESTS_MASK_ANY_RFO = 0x1000, // Offcore RFO requests
		OFFCORE_REQUESTS_MASK_DEMAND_READ_CODE = 0x200, // Offcore demand code read requests
		OFFCORE_REQUESTS_MASK_DEMAND_READ_DATA = 0x100, // Offcore demand data read requests
		OFFCORE_REQUESTS_MASK_DEMAND_RFO = 0x400, // Offcore demand RFO requests
		OFFCORE_REQUESTS_MASK_L1D_WRITEBACK = 0x4000, // Offcore L1 data cache writebacks
		LOAD_BLOCK = 0x3, // Loads blocked
		LOAD_BLOCK_MASK_OVERLAP_STORE = 0x200, // Loads that partially overlap an earlier store
		MISALIGN_MEMORY = 0x5, // Misaligned accesses
		MISALIGN_MEMORY_MASK_STORE = 0x200, // Store referenced with misaligned address
		INST_QUEUE_WRITE_CYCLES = 0x11e, // Cycles instructions are written to the instruction queue
		LSD_OVERFLOW = 0x120, // Number of loops that cannot stream from the instruction queue.
		MACHINE_CLEARS = 0xc3, // Machine clear asserted
		MACHINE_CLEARS_MASK_MEM_ORDER = 0x200, // Execution pipeline restart due to Memory ordering conflicts
		MACHINE_CLEARS_MASK_CYCLES = 0x100, // Cycles machine clear is asserted
		MACHINE_CLEARS_MASK_SMC = 0x400, // Self-modifying code detected
		FP_COMP_OPS_EXE = 0x10, // SSE/MMX micro-ops
		FP_COMP_OPS_EXE_MASK_MMX = 0x200, // MMX Uops
		FP_COMP_OPS_EXE_MASK_SSE_DOUBLE_PRECISION = 0x8000, // SSE FP double precision Uops
		FP_COMP_OPS_EXE_MASK_SSE_FP = 0x400, // SSE and SSE2 FP Uops
		FP_COMP_OPS_EXE_MASK_SSE_FP_PACKED = 0x1000, // SSE FP packed Uops
		FP_COMP_OPS_EXE_MASK_SSE_FP_SCALAR = 0x2000, // SSE FP scalar Uops
		FP_COMP_OPS_EXE_MASK_SSE_SINGLE_PRECISION = 0x4000, // SSE FP single precision Uops
		FP_COMP_OPS_EXE_MASK_SSE2_INTEGER = 0x800, // SSE2 integer Uops
		FP_COMP_OPS_EXE_MASK_X87 = 0x100, // Computational floating-point operations executed
		ITLB_FLUSH = 0x1ae, // ITLB flushes
		BR_INST_RETIRED = 0xc4, // Retired branch instructions (Precise Event)
		BR_INST_RETIRED_MASK_ALL_BRANCHES = 0x0, // Retired branch instructions (Precise Event)
		BR_INST_RETIRED_MASK_CONDITIONAL = 0x100, // Retired conditional branch instructions (Precise Event)
		BR_INST_RETIRED_MASK_NEAR_CALL = 0x200, // Retired near call instructions (Precise Event)
		L1D_CACHE_PREFETCH_LOCK_FB_HIT = 0x152, // L1D prefetch load lock accepted in fill buffer
		LARGE_ITLB = 0x82, // Large ITLB accesses
		LARGE_ITLB_MASK_HIT = 0x100, // Large ITLB hit
		LSD = 0xa8, // Loop stream detector
		LSD_MASK_UOPS = 0x100, // Counts the number of micro-ops delivered by LSD
		LSD_MASK_ACTIVE = 0x100 | (0x1 << INTEL_X86_CMASK_BIT), // Cycles is which at least one micro-op delivered by LSD
		LSD_MASK_INACTIVE = 0x100 | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles is which no micro-op is delivered by LSD
		L2_LINES_OUT = 0xf2, // L2 lines evicted
		L2_LINES_OUT_MASK_ANY = 0xf00, // L2 lines evicted
		L2_LINES_OUT_MASK_DEMAND_CLEAN = 0x100, // L2 lines evicted by a demand request
		L2_LINES_OUT_MASK_DEMAND_DIRTY = 0x200, // L2 modified lines evicted by a demand request
		L2_LINES_OUT_MASK_PREFETCH_CLEAN = 0x400, // L2 lines evicted by a prefetch request
		L2_LINES_OUT_MASK_PREFETCH_DIRTY = 0x800, // L2 modified lines evicted by a prefetch request
		ITLB_MISSES = 0x85, // ITLB miss
		ITLB_MISSES_MASK_ANY = 0x100, // ITLB miss
		ITLB_MISSES_MASK_WALK_COMPLETED = 0x200, // ITLB miss page walks
		ITLB_MISSES_MASK_WALK_CYCLES = 0x400, // ITLB miss page walk cycles
		ITLB_MISSES_MASK_LARGE_WALK_COMPLETED = 0x8000, // Number of completed large page walks due to misses in the STLB
		ITLB_MISSES_MASK_STLB_HIT = 0x1000, // ITLB misses hitting second level TLB
		L1D_PREFETCH = 0x4e, // L1D hardware prefetch
		L1D_PREFETCH_MASK_MISS = 0x200, // L1D hardware prefetch misses
		L1D_PREFETCH_MASK_REQUESTS = 0x100, // L1D hardware prefetch requests
		L1D_PREFETCH_MASK_TRIGGERS = 0x400, // L1D hardware prefetch requests triggered
		SQ_MISC = 0xf4, // Super Queue miscellaneous
		SQ_MISC_MASK_LRU_HINTS = 0x400, // Super Queue LRU hints sent to LLC
		SQ_MISC_MASK_SPLIT_LOCK = 0x1000, // Super Queue lock splits across a cache line
		SEG_RENAME_STALLS = 0x1d4, // Segment rename stall cycles
		FP_ASSIST = 0xf7, // X87 Floating point assists (Precise Event)
		FP_ASSIST_MASK_ALL = 0x100, // All X87 Floating point assists (Precise Event)
		FP_ASSIST_MASK_INPUT = 0x400, // X87 Floating point assists for invalid input value (Precise Event)
		FP_ASSIST_MASK_OUTPUT = 0x200, // X87 Floating point assists for invalid output value (Precise Event)
		SIMD_INT_128 = 0x12, // 128 bit SIMD operations
		SIMD_INT_128_MASK_PACK = 0x400, // 128 bit SIMD integer pack operations
		SIMD_INT_128_MASK_PACKED_ARITH = 0x2000, // 128 bit SIMD integer arithmetic operations
		SIMD_INT_128_MASK_PACKED_LOGICAL = 0x1000, // 128 bit SIMD integer logical operations
		SIMD_INT_128_MASK_PACKED_MPY = 0x100, // 128 bit SIMD integer multiply operations
		SIMD_INT_128_MASK_PACKED_SHIFT = 0x200, // 128 bit SIMD integer shift operations
		SIMD_INT_128_MASK_SHUFFLE_MOVE = 0x4000, // 128 bit SIMD integer shuffle/move operations
		SIMD_INT_128_MASK_UNPACK = 0x800, // 128 bit SIMD integer unpack operations
		OFFCORE_REQUESTS_OUTSTANDING = 0x60, // Outstanding offcore requests
		OFFCORE_REQUESTS_OUTSTANDING_MASK_ANY_READ = 0x800, // Outstanding offcore reads
		OFFCORE_REQUESTS_OUTSTANDING_MASK_DEMAND_READ_CODE = 0x200, // Outstanding offcore demand code reads
		OFFCORE_REQUESTS_OUTSTANDING_MASK_DEMAND_READ_DATA = 0x100, // Outstanding offcore demand data reads
		OFFCORE_REQUESTS_OUTSTANDING_MASK_DEMAND_RFO = 0x400, // Outstanding offcore demand RFOs
		OFFCORE_REQUESTS_OUTSTANDING_MASK_ANY_READ_NOT_EMPTY = 0x800 | (0x1 << INTEL_X86_CMASK_BIT), // Number of cycles with offcore reads busy
		OFFCORE_REQUESTS_OUTSTANDING_MASK_READ_DATA_NOT_EMPTY = 0x800 | (0x1 << INTEL_X86_CMASK_BIT), // Number of cycles with offcore demand data reads busy
		OFFCORE_REQUESTS_OUTSTANDING_MASK_READ_CODE_NOT_EMPTY = 0x200 | (0x1 << INTEL_X86_CMASK_BIT), // Number of cycles with offcore code reads busy
		OFFCORE_REQUESTS_OUTSTANDING_MASK_RFO_NOT_EMPTY = 0x200 | (0x1 << INTEL_X86_CMASK_BIT), // Number of cycles with offcore rfo busy
		MEM_STORE_RETIRED = 0xc, // Retired stores
		MEM_STORE_RETIRED_MASK_DTLB_MISS = 0x100, // Retired stores that miss the DTLB (Precise Event)
		INST_DECODED = 0x18, // Instructions decoded
		INST_DECODED_MASK_DEC0 = 0x100, // Instructions that must be decoded by decoder 0
		MACRO_INSTS_FUSIONS_DECODED = 0x1a6, // Count the number of instructions decoded that are macros-fused but not necessarily executed or retired
		MACRO_INSTS = 0xd0, // Macro-instructions
		MACRO_INSTS_MASK_DECODED = 0x100, // Instructions decoded
		PARTIAL_ADDRESS_ALIAS = 0x107, // False dependencies due to partial address aliasing
		ARITH = 0x14, // Counts arithmetic multiply and divide operations
		ARITH_MASK_CYCLES_DIV_BUSY = 0x100, // Counts the number of cycles the divider is busy executing divide or square root operations. The divide can be integer
		ARITH_MASK_DIV = 0x100 | INTEL_X86_MOD_EDGE | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Counts the number of divide or square root operations. The divide can be integer
		ARITH_MASK_MUL = 0x200, // Counts the number of multiply operations executed. This includes integer as well as floating point multiply operations but excludes DPPS mul and MPSAD. Count may be incorrect when HT is on
		L2_TRANSACTIONS = 0xf0, // L2 transactions
		L2_TRANSACTIONS_MASK_ANY = 0x8000, // All L2 transactions
		L2_TRANSACTIONS_MASK_FILL = 0x2000, // L2 fill transactions
		L2_TRANSACTIONS_MASK_IFETCH = 0x400, // L2 instruction fetch transactions
		L2_TRANSACTIONS_MASK_L1D_WB = 0x1000, // L1D writeback to L2 transactions
		L2_TRANSACTIONS_MASK_LOAD = 0x100, // L2 Load transactions
		L2_TRANSACTIONS_MASK_PREFETCH = 0x800, // L2 prefetch transactions
		L2_TRANSACTIONS_MASK_RFO = 0x200, // L2 RFO transactions
		L2_TRANSACTIONS_MASK_WB = 0x4000, // L2 writeback to LLC transactions
		INST_QUEUE_WRITES = 0x117, // Instructions written to instruction queue.
		SB_DRAIN = 0x4, // Store buffer
		SB_DRAIN_MASK_ANY = 0x700, // All Store buffer stall cycles
		LOAD_HIT_PRE = 0x14c, // Load operations conflicting with software prefetches
		MEM_UNCORE_RETIRED = 0xf, // Load instructions retired (Precise Event)
		MEM_UNCORE_RETIRED_MASK_LOCAL_HITM = 0x200, // Load instructions retired that HIT modified data in sibling core (Precise Event)
		MEM_UNCORE_RETIRED_MASK_LOCAL_DRAM_AND_REMOTE_CACHE_HIT = 0x800, // Load instructions retired local dram and remote cache HIT data sources (Precise Event)
		MEM_UNCORE_RETIRED_MASK_REMOTE_DRAM = 0x1000, // Load instructions retired remote DRAM and remote home-remote cache HITM (Precise Event)
		MEM_UNCORE_RETIRED_MASK_UNCACHEABLE = 0x8000, // Load instructions retired IO (Precise Event)
		MEM_UNCORE_RETIRED_MASK_REMOTE_HITM = 0x400, // Retired loads that hit remote socket in modified state (Precise Event)
		MEM_UNCORE_RETIRED_MASK_OTHER_LLC_MISS = 0x2000, // Load instructions retired other LLC miss (Precise Event)
		MEM_UNCORE_RETIRED_MASK_UNKNOWN_SOURCE = 0x100, // Load instructions retired unknown LLC miss (Precise Event)
		MEM_UNCORE_RETIRED_MASK_LOCAL_DRAM = 0x1000, // Retired loads with a data source of local DRAM or locally homed remote cache HITM (Precise Event)
		MEM_UNCORE_RETIRED_MASK_OTHER_CORE_L2_HITM = 0x200, // Retired loads instruction that hit modified data in sibling core (Precise Event)
		MEM_UNCORE_RETIRED_MASK_REMOTE_CACHE_LOCAL_HOME_HIT = 0x800, // Retired loads instruction that hit remote cache hit data source (Precise Event)
		MEM_UNCORE_RETIRED_MASK_REMOTE_DRAM = 0x2000, // Retired loads instruction remote DRAM and remote home-remote cache HITM (Precise Event)
		L2_DATA_RQSTS = 0x26, // All L2 data requests
		L2_DATA_RQSTS_MASK_ANY = 0xff00, // All L2 data requests
		L2_DATA_RQSTS_MASK_DEMAND_E_STATE = 0x400, // L2 data demand loads in E state
		L2_DATA_RQSTS_MASK_DEMAND_I_STATE = 0x100, // L2 data demand loads in I state (misses)
		L2_DATA_RQSTS_MASK_DEMAND_M_STATE = 0x800, // L2 data demand loads in M state
		L2_DATA_RQSTS_MASK_DEMAND_MESI = 0xf00, // L2 data demand requests
		L2_DATA_RQSTS_MASK_DEMAND_S_STATE = 0x200, // L2 data demand loads in S state
		L2_DATA_RQSTS_MASK_PREFETCH_E_STATE = 0x4000, // L2 data prefetches in E state
		L2_DATA_RQSTS_MASK_PREFETCH_I_STATE = 0x1000, // L2 data prefetches in the I state (misses)
		L2_DATA_RQSTS_MASK_PREFETCH_M_STATE = 0x8000, // L2 data prefetches in M state
		L2_DATA_RQSTS_MASK_PREFETCH_MESI = 0xf000, // All L2 data prefetches
		L2_DATA_RQSTS_MASK_PREFETCH_S_STATE = 0x2000, // L2 data prefetches in the S state
		BR_INST_EXEC = 0x88, // Branch instructions executed
		BR_INST_EXEC_MASK_ANY = 0x7f00, // Branch instructions executed
		BR_INST_EXEC_MASK_COND = 0x100, // Conditional branch instructions executed
		BR_INST_EXEC_MASK_DIRECT = 0x200, // Unconditional branches executed
		BR_INST_EXEC_MASK_DIRECT_NEAR_CALL = 0x1000, // Unconditional call branches executed
		BR_INST_EXEC_MASK_INDIRECT_NEAR_CALL = 0x2000, // Indirect call branches executed
		BR_INST_EXEC_MASK_INDIRECT_NON_CALL = 0x400, // Indirect non call branches executed
		BR_INST_EXEC_MASK_NEAR_CALLS = 0x3000, // Call branches executed
		BR_INST_EXEC_MASK_NON_CALLS = 0x700, // All non call branches executed
		BR_INST_EXEC_MASK_RETURN_NEAR = 0x800, // Indirect return branches executed
		BR_INST_EXEC_MASK_TAKEN = 0x4000, // Taken branches executed
		ITLB_MISS_RETIRED = 0x20c8, // Retired instructions that missed the ITLB (Precise Event)
		BPU_MISSED_CALL_RET = 0x1e5, // Branch prediction unit missed call or return
		SNOOPQ_REQUESTS_OUTSTANDING = 0xb3, // Outstanding snoop requests
		SNOOPQ_REQUESTS_OUTSTANDING_MASK_CODE = 0x400, // Outstanding snoop code requests
		SNOOPQ_REQUESTS_OUTSTANDING_MASK_CODE_NOT_EMPTY = 0x400 | (0x1 << INTEL_X86_CMASK_BIT), // Cycles snoop code requests queue not empty
		SNOOPQ_REQUESTS_OUTSTANDING_MASK_DATA = 0x100, // Outstanding snoop data requests
		SNOOPQ_REQUESTS_OUTSTANDING_MASK_DATA_NOT_EMPTY = 0x100 | (0x1 << INTEL_X86_CMASK_BIT), // Cycles snoop data requests queue not empty
		SNOOPQ_REQUESTS_OUTSTANDING_MASK_INVALIDATE = 0x200, // Outstanding snoop invalidate requests
		SNOOPQ_REQUESTS_OUTSTANDING_MASK_INVALIDATE_NOT_EMPTY = 0x200 | (0x1 << INTEL_X86_CMASK_BIT), // Cycles snoop invalidate requests queue not empty
		MEM_LOAD_RETIRED = 0xcb, // Memory loads retired (Precise Event)
		MEM_LOAD_RETIRED_MASK_DTLB_MISS = 0x8000, // Retired loads that miss the DTLB (Precise Event)
		MEM_LOAD_RETIRED_MASK_HIT_LFB = 0x4000, // Retired loads that miss L1D and hit an previously allocated LFB (Precise Event)
		MEM_LOAD_RETIRED_MASK_L1D_HIT = 0x100, // Retired loads that hit the L1 data cache (Precise Event)
		MEM_LOAD_RETIRED_MASK_L2_HIT = 0x200, // Retired loads that hit the L2 cache (Precise Event)
		MEM_LOAD_RETIRED_MASK_L3_MISS = 0x1000, // Retired loads that miss the LLC cache (Precise Event)
		MEM_LOAD_RETIRED_MASK_LLC_MISS = 0x1000, // This is an alias for L3_MISS
		MEM_LOAD_RETIRED_MASK_L3_UNSHARED_HIT = 0x400, // Retired loads that hit valid versions in the LLC cache (Precise Event)
		MEM_LOAD_RETIRED_MASK_LLC_UNSHARED_HIT = 0x400, // This is an alias for L3_UNSHARED_HIT
		MEM_LOAD_RETIRED_MASK_OTHER_CORE_L2_HIT_HITM = 0x800, // Retired loads that hit sibling core's L2 in modified or unmodified states (Precise Event)
		L1I = 0x80, // L1I instruction fetch
		L1I_MASK_CYCLES_STALLED = 0x400, // L1I instruction fetch stall cycles
		L1I_MASK_HITS = 0x100, // L1I instruction fetch hits
		L1I_MASK_MISSES = 0x200, // L1I instruction fetch misses
		L1I_MASK_READS = 0x300, // L1I Instruction fetches
		L2_WRITE = 0x27, // L2 demand lock/store RFO
		L2_WRITE_MASK_LOCK_E_STATE = 0x4000, // L2 demand lock RFOs in E state
		L2_WRITE_MASK_LOCK_HIT = 0xe000, // All demand L2 lock RFOs that hit the cache
		L2_WRITE_MASK_LOCK_I_STATE = 0x1000, // L2 demand lock RFOs in I state (misses)
		L2_WRITE_MASK_LOCK_M_STATE = 0x8000, // L2 demand lock RFOs in M state
		L2_WRITE_MASK_LOCK_MESI = 0xf000, // All demand L2 lock RFOs
		L2_WRITE_MASK_LOCK_S_STATE = 0x2000, // L2 demand lock RFOs in S state
		L2_WRITE_MASK_RFO_HIT = 0xe00, // All L2 demand store RFOs that hit the cache
		L2_WRITE_MASK_RFO_I_STATE = 0x100, // L2 demand store RFOs in I state (misses)
		L2_WRITE_MASK_RFO_M_STATE = 0x800, // L2 demand store RFOs in M state
		L2_WRITE_MASK_RFO_MESI = 0xf00, // All L2 demand store RFOs
		L2_WRITE_MASK_RFO_S_STATE = 0x200, // L2 demand store RFOs in S state
		SNOOP_RESPONSE = 0xb8, // Snoop
		SNOOP_RESPONSE_MASK_HIT = 0x100, // Thread responded HIT to snoop
		SNOOP_RESPONSE_MASK_HITE = 0x200, // Thread responded HITE to snoop
		SNOOP_RESPONSE_MASK_HITM = 0x400, // Thread responded HITM to snoop
		L1D = 0x51, // L1D cache
		L1D_MASK_M_EVICT = 0x400, // L1D cache lines replaced in M state
		L1D_MASK_M_REPL = 0x200, // L1D cache lines allocated in the M state
		L1D_MASK_M_SNOOP_EVICT = 0x800, // L1D snoop eviction of cache lines in M state
		L1D_MASK_REPL = 0x100, // L1 data cache lines allocated
		RESOURCE_STALLS = 0xa2, // Resource related stall cycles
		RESOURCE_STALLS_MASK_ANY = 0x100, // Resource related stall cycles
		RESOURCE_STALLS_MASK_FPCW = 0x2000, // FPU control word write stall cycles
		RESOURCE_STALLS_MASK_LOAD = 0x200, // Load buffer stall cycles
		RESOURCE_STALLS_MASK_MXCSR = 0x4000, // MXCSR rename stall cycles
		RESOURCE_STALLS_MASK_OTHER = 0x8000, // Other Resource related stall cycles
		RESOURCE_STALLS_MASK_ROB_FULL = 0x1000, // ROB full stall cycles
		RESOURCE_STALLS_MASK_RS_FULL = 0x400, // Reservation Station full stall cycles
		RESOURCE_STALLS_MASK_STORE = 0x800, // Store buffer stall cycles
		RAT_STALLS = 0xd2, // All RAT stall cycles
		RAT_STALLS_MASK_ANY = 0xf00, // All RAT stall cycles
		RAT_STALLS_MASK_FLAGS = 0x100, // Flag stall cycles
		RAT_STALLS_MASK_REGISTERS = 0x200, // Partial register stall cycles
		RAT_STALLS_MASK_ROB_READ_PORT = 0x400, // ROB read port stalls cycles
		RAT_STALLS_MASK_SCOREBOARD = 0x800, // Scoreboard stall cycles
		CPU_CLK_UNHALTED = 0x3c, // Cycles when processor is not in halted state
		CPU_CLK_UNHALTED_MASK_THREAD_P = 0x0, // Cycles when thread is not halted (programmable counter)
		CPU_CLK_UNHALTED_MASK_REF_P = 0x100, // Reference base clock (133 Mhz) cycles when thread is not halted
		CPU_CLK_UNHALTED_MASK_TOTAL_CYCLES = 0x0 | INTEL_X86_MOD_INV | (0x2 << INTEL_X86_CMASK_BIT), // Total number of elapsed cycles. Does not work when C-state enabled
		L1D_WB_L2 = 0x28, // L1D writebacks to L2
		L1D_WB_L2_MASK_E_STATE = 0x400, // L1 writebacks to L2 in E state
		L1D_WB_L2_MASK_I_STATE = 0x100, // L1 writebacks to L2 in I state (misses)
		L1D_WB_L2_MASK_M_STATE = 0x800, // L1 writebacks to L2 in M state
		L1D_WB_L2_MASK_MESI = 0xf00, // All L1 writebacks to L2
		L1D_WB_L2_MASK_S_STATE = 0x200, // L1 writebacks to L2 in S state
		MISPREDICTED_BRANCH_RETIRED = 0xc5, // Count mispredicted branch instructions at retirement. Specifically
		THREAD_ACTIVE = 0x1ec, // Cycles thread is active
		UOP_UNFUSION = 0x1db, // Counts unfusion events due to floating point exception to a fused uop
		OFFCORE_RESPONSE_0 = 0x1b7, // Offcore response 0 (must provide at least one request and one response umasks)
		OFFCORE_RESPONSE_0_MASK_DMND_DATA_RD = 0x100, // Request: counts the number of demand and DCU prefetch data reads of full and partial cachelines as well as demand data page table entry cacheline reads. Does not count L2 data read prefetches or instruction fetches
		OFFCORE_RESPONSE_0_MASK_DMND_RFO = 0x200, // Request: counts the number of demand and DCU prefetch reads for ownership (RFO) requests generated by a write to data cacheline. Does not count L2 RFO
		OFFCORE_RESPONSE_0_MASK_DMND_IFETCH = 0x400, // Request: counts the number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches
		OFFCORE_RESPONSE_0_MASK_WB = 0x800, // Request: counts the number of writeback (modified to exclusive) transactions
		OFFCORE_RESPONSE_0_MASK_PF_DATA_RD = 0x1000, // Request: counts the number of data cacheline reads generated by L2 prefetchers
		OFFCORE_RESPONSE_0_MASK_PF_RFO = 0x2000, // Request: counts the number of RFO requests generated by L2 prefetchers
		OFFCORE_RESPONSE_0_MASK_PF_IFETCH = 0x4000, // Request: counts the number of code reads generated by L2 prefetchers
		OFFCORE_RESPONSE_0_MASK_OTHER = 0x8000, // Request: counts one of the following transaction types
		OFFCORE_RESPONSE_0_MASK_ANY_IFETCH = 0x4400, // Request: combination of PF_IFETCH | DMND_IFETCH
		OFFCORE_RESPONSE_0_MASK_ANY_REQUEST = 0xff00, // Request: combination of all requests umasks
		OFFCORE_RESPONSE_0_MASK_ANY_DATA = 0x3300, // Request: any data read/write request
		OFFCORE_RESPONSE_0_MASK_ANY_DATA_RD = 0x1100, // Request: any data read in request
		OFFCORE_RESPONSE_0_MASK_ANY_RFO = 0x2200, // Request: combination of DMND_RFO | PF_RFO
		OFFCORE_RESPONSE_0_MASK_UNCORE_HIT = 0x10000, // Response: counts L3 Hit: local or remote home requests that hit L3 cache in the uncore with no coherency actions required (snooping)
		OFFCORE_RESPONSE_0_MASK_OTHER_CORE_HIT_SNP = 0x20000, // Response: counts L3 Hit: local or remote home requests that hit L3 cache in the uncore and was serviced by another core with a cross core snoop where no modified copies were found (clean)
		OFFCORE_RESPONSE_0_MASK_OTHER_CORE_HITM = 0x40000, // Response: counts L3 Hit: local or remote home requests that hit L3 cache in the uncore and was serviced by another core with a cross core snoop where modified copies were found (HITM)
		OFFCORE_RESPONSE_0_MASK_REMOTE_CACHE_HITM = 0x80000, // Response: counts L3 Hit: local or remote home requests that hit a remote L3 cacheline in modified (HITM) state
		OFFCORE_RESPONSE_0_MASK_REMOTE_CACHE_FWD = 0x100000, // Response: counts L3 Miss: local homed requests that missed the L3 cache and was serviced by forwarded data following a cross package snoop where no modified copies found. (Remote home requests are not counted)
		OFFCORE_RESPONSE_0_MASK_LOCAL_DRAM_AND_REMOTE_CACHE_HIT = 0x100000, // Response: counts L3 Miss: local home requests that missed the L3 cache and were serviced by local DRAM or a remote cache
		OFFCORE_RESPONSE_0_MASK_REMOTE_DRAM = 0x200000, // Response: counts L3 Miss: remote home requests that missed the L3 cache and were serviced by remote DRAM
		OFFCORE_RESPONSE_0_MASK_LOCAL_DRAM = 0x200000, // Response: counts L3 Miss: local home requests that missed the L3 cache and were serviced by local DRAM
		OFFCORE_RESPONSE_0_MASK_REMOTE_DRAM = 0x400000, // Response: counts L3 Miss: remote home requests that missed the L3 cache and were serviced by remote DRAM
		OFFCORE_RESPONSE_0_MASK_OTHER_LLC_MISS = 0x400000, // Response: counts L3 Miss: remote home requests that missed the L3 cache
		OFFCORE_RESPONSE_0_MASK_NON_DRAM = 0x800000, // Response: Non-DRAM requests that were serviced by IOH
		OFFCORE_RESPONSE_0_MASK_ANY_CACHE_DRAM = 0x7f0000, // Response: requests serviced by any source but IOH
		OFFCORE_RESPONSE_0_MASK_ANY_CACHE_DRAM = 0x7f0000, // Response: requests serviced by any source but IOH
		OFFCORE_RESPONSE_0_MASK_ANY_DRAM = 0x600000, // Response: requests serviced by local or remote DRAM
		OFFCORE_RESPONSE_0_MASK_ANY_LLC_MISS = 0xf80000, // Response: requests that missed in L3
		OFFCORE_RESPONSE_0_MASK_ANY_LLC_MISS = 0xf80000, // Response: requests that missed in L3
		OFFCORE_RESPONSE_0_MASK_LOCAL_CACHE_DRAM = 0x270000, // Response: requests hit local core or uncore caches or local DRAM
		OFFCORE_RESPONSE_0_MASK_REMOTE_CACHE_DRAM = 0x580000, // Response: requests that miss L3 and hit remote caches or DRAM
		OFFCORE_RESPONSE_0_MASK_LOCAL_CACHE = 0x70000, // Response: any local (core and socket) caches
		OFFCORE_RESPONSE_0_MASK_ANY_RESPONSE = 0xff0000, // Response: combination of all response umasks
		OFFCORE_RESPONSE_0_MASK_ANY_RESPONSE = 0xff0000, // Response: combination of all response umasks
		OFFCORE_RESPONSE_1 = 0x1bb, // Offcore response 1 (must provide at least one request and one response umasks)
		OFFCORE_RESPONSE_1_MASK_DMND_DATA_RD = 0x100, // Request: counts the number of demand and DCU prefetch data reads of full and partial cachelines as well as demand data page table entry cacheline reads. Does not count L2 data read prefetches or instruction fetches
		OFFCORE_RESPONSE_1_MASK_DMND_RFO = 0x200, // Request: counts the number of demand and DCU prefetch reads for ownership (RFO) requests generated by a write to data cacheline. Does not count L2 RFO
		OFFCORE_RESPONSE_1_MASK_DMND_IFETCH = 0x400, // Request: counts the number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches
		OFFCORE_RESPONSE_1_MASK_WB = 0x800, // Request: counts the number of writeback (modified to exclusive) transactions
		OFFCORE_RESPONSE_1_MASK_PF_DATA_RD = 0x1000, // Request: counts the number of data cacheline reads generated by L2 prefetchers
		OFFCORE_RESPONSE_1_MASK_PF_RFO = 0x2000, // Request: counts the number of RFO requests generated by L2 prefetchers
		OFFCORE_RESPONSE_1_MASK_PF_IFETCH = 0x4000, // Request: counts the number of code reads generated by L2 prefetchers
		OFFCORE_RESPONSE_1_MASK_OTHER = 0x8000, // Request: counts one of the following transaction types
		OFFCORE_RESPONSE_1_MASK_ANY_IFETCH = 0x4400, // Request: combination of PF_IFETCH | DMND_IFETCH
		OFFCORE_RESPONSE_1_MASK_ANY_REQUEST = 0xff00, // Request: combination of all requests umasks
		OFFCORE_RESPONSE_1_MASK_ANY_DATA = 0x3300, // Request: any data read/write request
		OFFCORE_RESPONSE_1_MASK_ANY_DATA_RD = 0x1100, // Request: any data read in request
		OFFCORE_RESPONSE_1_MASK_ANY_RFO = 0x2200, // Request: combination of DMND_RFO | PF_RFO
		OFFCORE_RESPONSE_1_MASK_UNCORE_HIT = 0x10000, // Response: counts L3 Hit: local or remote home requests that hit L3 cache in the uncore with no coherency actions required (snooping)
		OFFCORE_RESPONSE_1_MASK_OTHER_CORE_HIT_SNP = 0x20000, // Response: counts L3 Hit: local or remote home requests that hit L3 cache in the uncore and was serviced by another core with a cross core snoop where no modified copies were found (clean)
		OFFCORE_RESPONSE_1_MASK_OTHER_CORE_HITM = 0x40000, // Response: counts L3 Hit: local or remote home requests that hit L3 cache in the uncore and was serviced by another core with a cross core snoop where modified copies were found (HITM)
		OFFCORE_RESPONSE_1_MASK_REMOTE_CACHE_HITM = 0x80000, // Response: counts L3 Hit: local or remote home requests that hit a remote L3 cacheline in modified (HITM) state
		OFFCORE_RESPONSE_1_MASK_REMOTE_CACHE_FWD = 0x100000, // Response: counts L3 Miss: local homed requests that missed the L3 cache and was serviced by forwarded data following a cross package snoop where no modified copies found. (Remote home requests are not counted)
		OFFCORE_RESPONSE_1_MASK_LOCAL_DRAM_AND_REMOTE_CACHE_HIT = 0x100000, // Response: counts L3 Miss: local home requests that missed the L3 cache and were serviced by local DRAM or a remote cache
		OFFCORE_RESPONSE_1_MASK_REMOTE_DRAM = 0x200000, // Response: counts L3 Miss: remote home requests that missed the L3 cache and were serviced by remote DRAM
		OFFCORE_RESPONSE_1_MASK_LOCAL_DRAM = 0x200000, // Response: counts L3 Miss: local home requests that missed the L3 cache and were serviced by local DRAM
		OFFCORE_RESPONSE_1_MASK_REMOTE_DRAM = 0x400000, // Response: counts L3 Miss: remote home requests that missed the L3 cache and were serviced by remote DRAM
		OFFCORE_RESPONSE_1_MASK_OTHER_LLC_MISS = 0x400000, // Response: counts L3 Miss: remote home requests that missed the L3 cache
		OFFCORE_RESPONSE_1_MASK_NON_DRAM = 0x800000, // Response: Non-DRAM requests that were serviced by IOH
		OFFCORE_RESPONSE_1_MASK_ANY_CACHE_DRAM = 0x7f0000, // Response: requests serviced by any source but IOH
		OFFCORE_RESPONSE_1_MASK_ANY_CACHE_DRAM = 0x7f0000, // Response: requests serviced by any source but IOH
		OFFCORE_RESPONSE_1_MASK_ANY_DRAM = 0x600000, // Response: requests serviced by local or remote DRAM
		OFFCORE_RESPONSE_1_MASK_ANY_LLC_MISS = 0xf80000, // Response: requests that missed in L3
		OFFCORE_RESPONSE_1_MASK_ANY_LLC_MISS = 0xf80000, // Response: requests that missed in L3
		OFFCORE_RESPONSE_1_MASK_LOCAL_CACHE_DRAM = 0x270000, // Response: requests hit local core or uncore caches or local DRAM
		OFFCORE_RESPONSE_1_MASK_REMOTE_CACHE_DRAM = 0x580000, // Response: requests that miss L3 and hit remote caches or DRAM
		OFFCORE_RESPONSE_1_MASK_LOCAL_CACHE = 0x70000, // Response: any local (core and socket) caches
		OFFCORE_RESPONSE_1_MASK_ANY_RESPONSE = 0xff0000, // Response: combination of all response umasks
		OFFCORE_RESPONSE_1_MASK_ANY_RESPONSE = 0xff0000, // Response: combination of all response umasks
		};};