#include <cstdint>

namespace optkit::intel{
	enum class slm : uint64_t {
		UNHALTED_CORE_CYCLES = 0x3c, // Unhalted core cycles
		UNHALTED_REFERENCE_CYCLES = 0x0300, // Unhalted reference cycle
		INSTRUCTION_RETIRED = 0xc0, // Instructions retired
		INSTRUCTIONS_RETIRED = 0xc0, // This is an alias for INSTRUCTION_RETIRED
		LLC_REFERENCES = 0x4f2e, // Last level of cache references
		LAST_LEVEL_CACHE_REFERENCES = 0x4f2e, // This is an alias for LLC_REFERENCES
		LLC_MISSES = 0x412e, // Last level of cache misses
		LAST_LEVEL_CACHE_MISSES = 0x412e, // This is an alias for LLC_MISSES
		BRANCH_INSTRUCTIONS_RETIRED = 0xc4, // Branch instructions retired
		MISPREDICTED_BRANCH_RETIRED = 0xc5, // Mispredicted branch instruction retired
		DECODE_RESTRICTION = 0xe9, // Instruction length prediction delay
		DECODE_RESTRICTION_MASK_PREDECODE_WRONG = 0x0100, // Number of times the prediction (from the predecode cache) for instruction length is incorrect
		L2_REJECT_XQ = 0x30, // Rejected L2 requests to XQ
		L2_REJECT_XQ_MASK_ALL = 0x000, // Number of demand and prefetch transactions that the L2 XQ rejects due to a full or near full condition which likely indicates back pressure from the IDI link. The XQ may reject transactions from the L2Q (non-cacheable requests)
		ICACHE = 0x80, // Instruction fetches
		ICACHE_MASK_ACCESSES = 0x300, // Instruction fetches
		ICACHE_MASK_MISSES = 0x200, // Count all instructions fetches that miss the icache or produce memory requests. This includes uncacheache fetches. Any instruction fetch miss is counted only once and not once for every cycle it is outstanding
		ICACHE_MASK_HIT = 0x100, // Count all instructions fetches from the instruction cache
		UOPS_RETIRED = 0xc2, // Micro-ops retired
		UOPS_RETIRED_MASK_ANY = 0x1000, // Micro-ops retired
		UOPS_RETIRED_MASK_MS = 0x0100, // Micro-ops retired that were supplied fro MSROM
		UOPS_RETIRED_MASK_STALLED_CYCLES = 0x1000 | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Cycles no micro-ops retired
		UOPS_RETIRED_MASK_STALLS = 0x1000 | INTEL_X86_MOD_EDGE | INTEL_X86_MOD_INV | (0x1 << INTEL_X86_CMASK_BIT), // Periods no micro-ops retired
		INST_RETIRED = 0xc0, // Instructions retired
		INST_RETIRED_MASK_ANY_P = 0x0, // Instructions retired using generic counter (precise event)
		INST_RETIRED_MASK_ANY = 0x0, // Instructions retired using generic counter (precise event)
		CYCLES_DIV_BUSY = 0xcd, // Cycles the divider is busy
		CYCLES_DIV_BUSY_MASK_ANY = 0x0100, // Number of cycles the divider is busy
		RS_FULL_STALL = 0xcb, // RS full
		RS_FULL_STALL_MASK_MEC = 0x0100, // Number of cycles when the allocation pipeline is stalled due to the RS for the MEC cluster is full
		RS_FULL_STALL_MASK_ALL = 0x1f00, // Number of cycles when the allocation pipeline is stalled due any one of the RS being full
		RS_FULL_STALL_MASK_ANY = 0x1f00, // Number of cycles when the allocation pipeline is stalled due any one of the RS being full
		LLC_RQSTS = 0x2e, // L2 cache requests
		LLC_RQSTS_MASK_MISS = 0x4100, // Number of L2 cache misses
		LLC_RQSTS_MASK_ANY = 0x4f00, // Number of L2 cache references
		MACHINE_CLEARS = 0xc3, // Self-Modifying Code detected
		MACHINE_CLEARS_MASK_SMC = 0x100, // Self-Modifying Code detected
		MACHINE_CLEARS_MASK_MEMORY_ORDERING = 0x200, // Number of stalled cycles due to memory ordering
		MACHINE_CLEARS_MASK_FP_ASSIST = 0x400, // Number of stalled cycle due to FPU assist
		MACHINE_CLEARS_MASK_ALL = 0x800, // Count any the machine clears
		MACHINE_CLEARS_MASK_ANY = 0x800, // Count any the machine clears
		BR_INST_RETIRED = 0xc4, // Retired branch instructions
		BR_INST_RETIRED_MASK_ANY = 0x0, // Any retired branch instruction (Precise Event)
		BR_INST_RETIRED_MASK_ALL_BRANCHES = 0x0, // Any Retired branch instruction (Precise Event)
		BR_INST_RETIRED_MASK_ALL_TAKEN_BRANCHES = 0x8000, // Retired branch instructions (Precise Event)
		BR_INST_RETIRED_MASK_JCC = 0x7e00, // JCC instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_TAKEN_JCC = 0xfe00, // Taken JCC instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_CALL = 0xf900, // Near call instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_REL_CALL = 0xfd00, // Near relative call instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_IND_CALL = 0xfb00, // Near indirect call instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_RETURN = 0xf700, // Near ret instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_NON_RETURN_IND = 0xeb00, // Number of near indirect jmp and near indirect call instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_FAR_BRANCH = 0xbf00, // Far branch instructions retired (Precise Event)
		BR_INST_RETIRED_MASK_FAR = 0xbf00, // Far branch instructions retired (Precise Event)
		BR_MISP_RETIRED = 0xc5, // Mispredicted retired branch instructions (Precise Event)
		BR_MISP_RETIRED_MASK_ALL_BRANCHES = 0x0000, // All mispredicted branches (Precise Event)
		BR_MISP_RETIRED_MASK_ANY = 0x0000, // All mispredicted branches (Precise Event)
		BR_MISP_RETIRED_MASK_JCC = 0x7e00, // Number of mispredicted conditional branch instructions retired (Precise Event)
		BR_MISP_RETIRED_MASK_NON_RETURN_IND = 0xeb00, // Number of mispredicted non-return branch instructions retired (Precise Event)
		BR_MISP_RETIRED_MASK_RETURN = 0xf700, // Number of mispredicted return branch instructions retired (Precise Event)
		BR_MISP_RETIRED_MASK_IND_CALL = 0xfb00, // Number of mispredicted indirect call branch instructions retired (Precise Event)
		BR_MISP_RETIRED_MASK_TAKEN_JCC = 0xfe00, // Number of mispredicted taken conditional branch instructions retired (Precise Event)
		BR_MISP_INST_RETIRED = 0xc5, // Mispredicted retired branch instructions (Precise Event)
		BR_MISP_INST_RETIRED_MASK_ALL_BRANCHES = 0x0000, // All mispredicted branches (Precise Event)
		BR_MISP_INST_RETIRED_MASK_ANY = 0x0000, // All mispredicted branches (Precise Event)
		BR_MISP_INST_RETIRED_MASK_JCC = 0x7e00, // Number of mispredicted conditional branch instructions retired (Precise Event)
		BR_MISP_INST_RETIRED_MASK_NON_RETURN_IND = 0xeb00, // Number of mispredicted non-return branch instructions retired (Precise Event)
		BR_MISP_INST_RETIRED_MASK_RETURN = 0xf700, // Number of mispredicted return branch instructions retired (Precise Event)
		BR_MISP_INST_RETIRED_MASK_IND_CALL = 0xfb00, // Number of mispredicted indirect call branch instructions retired (Precise Event)
		BR_MISP_INST_RETIRED_MASK_TAKEN_JCC = 0xfe00, // Number of mispredicted taken conditional branch instructions retired (Precise Event)
		MS_DECODED = 0xe7, // MS decoder
		MS_DECODED_MASK_ENTRY = 0x0100, // Number of times the MSROM starts a flow of uops
		BACLEARS = 0xe6, // Branch address calculator
		BACLEARS_MASK_ANY = 0x100, // BACLEARS asserted
		BACLEARS_MASK_ALL = 0x100, // BACLEARS asserted
		BACLEARS_MASK_RETURN = 0x800, // Number of baclears for return branches
		BACLEARS_MASK_COND = 0x1000, // Number of baclears for conditional branches
		NO_ALLOC_CYCLES = 0xca, // Front-end allocation
		NO_ALLOC_CYCLES_MASK_ANY = 0x3f00, // Number of cycles when the front-end does not provide any instructions to be allocated for any reason
		NO_ALLOC_CYCLES_MASK_ALL = 0x3f00, // Number of cycles when the front-end does not provide any instructions to be allocated for any reason
		NO_ALLOC_CYCLES_MASK_NOT_DELIVERED = 0x5000, // Number of cycles when the front-end does not provide any instructions to be allocated but the back-end is not stalled
		NO_ALLOC_CYCLES_MASK_MISPREDICTS = 0x400, // Number of cycles when no uops are allocated and the alloc pipe is stalled waiting for a mispredicted jump to retire
		NO_ALLOC_CYCLES_MASK_RAT_STALL = 0x2000, // Number of cycles when no uops are allocated and a RAT stall is asserted
		NO_ALLOC_CYCLES_MASK_ROB_FULL = 0x0100, // Number of cycles when no uops are allocated and the ROB is full (less than 2 entries available)
		CPU_CLK_UNHALTED = 0x3c, // Core cycles when core is not halted
		CPU_CLK_UNHALTED_MASK_CORE_P = 0x0, // Core cycles when core is not halted
		CPU_CLK_UNHALTED_MASK_BUS = 0x100, // Bus cycles when core is not halted. This event can give a measurement of the elapsed time. This events has a constant ratio with CPU_CLK_UNHALTED:REF event
		CPU_CLK_UNHALTED_MASK_REF = 0x100, // Number of reference cycles that the core is not in a halted state. The core enters the halted state when it is running the HLT instruction. In mobile systems
		MEM_UOP_RETIRED = 0x4, // Retired loads micro-ops
		MEM_UOP_RETIRED_MASK_LD_DCU_MISS = 0x100, // Number of load uops retired that miss in L1 data cache. Note that prefetch misses will not be counted
		MEM_UOP_RETIRED_MASK_LD_L2_HIT = 0x200, // Number of load uops retired that hit L2 (Precise Event)
		MEM_UOP_RETIRED_MASK_LD_L2_MISS = 0x400, // Number of load uops retired that missed L2 (Precise Event)
		MEM_UOP_RETIRED_MASK_LD_DTLB_MISS = 0x800, // Number of load uops retired that had a DTLB miss (Precise Event)
		MEM_UOP_RETIRED_MASK_LD_UTLB_MISS = 0x1000, // Number of load uops retired that had a UTLB miss
		MEM_UOP_RETIRED_MASK_HITM = 0x2000, // Number of load uops retired that got data from the other core or from the other module and the line was modified (Precise Event)
		MEM_UOP_RETIRED_MASK_ANY_LD = 0x4000, // Number of load uops retired
		MEM_UOP_RETIRED_MASK_ANY_ST = 0x8000, // Number of store uops retired
		CORE_REJECT_L2Q = 0x31, // Demand and L1 prefetcher requests rejected by L2
		CORE_REJECT_L2Q_MASK_ALL = 0x0000, // Number of requests that were not accepted into the L2Q because the L2Q was FULL
		REHABQ = 0x03, // Memory reference queue
		REHABQ_MASK_LD_BLOCK_ST_FORWARD = 0x0100, // Number of retired loads that were prohibited from receiving forwarded data from the store because of address mismatch (Precise Event)
		REHABQ_MASK_LD_BLOCK_STD_NOTREADY = 0x0200, // Number of times forward was technically possible but did not occur because the store data was not available at the right time
		REHABQ_MASK_ST_SPLITS = 0x0400, // Number of retired stores that experienced cache line boundary splits
		REHABQ_MASK_LD_SPLITS = 0x0800, // Number of retired loads that experienced cache line boundary splits (Precise Event)
		REHABQ_MASK_LOCK = 0x1000, // Number of retired memory operations with lock semantics. These are either implicit locked instructions such as XCHG or instructions with an explicit LOCK prefix
		REHABQ_MASK_STA_FULL = 0x2000, // Number of retired stores that are delayed because there is not a store address buffer available
		REHABQ_MASK_ANY_LD = 0x4000, // Number of load uops reissued from RehabQ
		REHABQ_MASK_ANY_ST = 0x8000, // Number of store uops reissued from RehabQ
		FETCH_STALL = 0x86, // Fetch stalls
		FETCH_STALL_MASK_ICACHE_FILL_PENDING_CYCLES = 0x0400, // Number of cycles the NIP stalls because of an icache miss. This is a cumulative count of cycles the NIP stalled for all icache misses
		PAGE_WALKS = 0x5, // Page walker
		PAGE_WALKS_MASK_CYCLES = 0x0300, // Total cycles for all the page walks. (I-side and D-side)
		PAGE_WALKS_MASK_WALKS = 0x0300 | INTEL_X86_MOD_EDGE, // Total number of page walks. (I-side and D-side)
		PAGE_WALKS_MASK_D_SIDE_CYCLES = 0x0100, // Number of cycles when a D-side page walk is in progress
		PAGE_WALKS_MASK_D_SIDE_WALKS = 0x0100 | INTEL_X86_MOD_EDGE, // Number of D-side page walks
		PAGE_WALKS_MASK_I_SIDE_CYCLES = 0x0200, // Number of cycles when a I-side page walk is in progress
		PAGE_WALKS_MASK_I_SIDE_WALKS = 0x0200 | INTEL_X86_MOD_EDGE, // Number of I-side page walks
		OFFCORE_RESPONSE_0 = 0x01b7, // Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)
		OFFCORE_RESPONSE_0_MASK_DMND_DATA_RD = 1ULL << (0 + 8), // Request: number of demand and DCU prefetch data reads of full and partial cachelines as well as demand data page table entry cacheline reads. Does not count L2 data read prefetches or instruction fetches
		OFFCORE_RESPONSE_0_MASK_DMND_RFO = 1ULL << (1 + 8), // Request: number of demand and DCU prefetch reads for ownership (RFO) requests generated by a write to data cacheline. Does not count L2 RFO prefetches
		OFFCORE_RESPONSE_0_MASK_DMND_IFETCH = 1ULL << (2 + 8), // Request: number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches
		OFFCORE_RESPONSE_0_MASK_WB = 1ULL << (3 + 8), // Request: number of writebacks (modified to exclusive) transactions
		OFFCORE_RESPONSE_0_MASK_PF_L2_DATA_RD = 1ULL << (4 + 8), // Request: number of data cacheline reads generated by L2 prefetchers
		OFFCORE_RESPONSE_0_MASK_PF_RFO = 1ULL << (5 + 8), // Request: number of RFO requests generated by L2 prefetchers
		OFFCORE_RESPONSE_0_MASK_PF_IFETCH = 1ULL << (6 + 8), // Request: number of code reads generated by L2 prefetchers
		OFFCORE_RESPONSE_0_MASK_PARTIAL_READ = 1ULL << (7 + 8), // Request: number of demand reads of partial cachelines (including UC
		OFFCORE_RESPONSE_0_MASK_PARTIAL_WRITE = 1ULL << (8 + 8), // Request: number of demand RFO requests to write to partial cache lines (includes UC
		OFFCORE_RESPONSE_0_MASK_UC_IFETCH = 1ULL << (9 + 8), // Request: number of UC instruction fetches
		OFFCORE_RESPONSE_0_MASK_BUS_LOCKS = 1ULL << (10 + 8), // Request: number bus lock and split lock requests
		OFFCORE_RESPONSE_0_MASK_STRM_ST = 1ULL << (11 + 8), // Request: number of streaming store requests
		OFFCORE_RESPONSE_0_MASK_SW_PREFETCH = 1ULL << (12 + 8), // Request: number of software prefetch requests
		OFFCORE_RESPONSE_0_MASK_PF_L1_DATA_RD = 1ULL << (13 + 8), // Request: number of data cacheline reads generated by L1 prefetchers
		OFFCORE_RESPONSE_0_MASK_PARTIAL_STRM_ST = 1ULL << (14 + 8), // Request: number of partial streaming store requests
		OFFCORE_RESPONSE_0_MASK_OTHER = 1ULL << (15+8), // Request: counts one any other request that crosses IDI
		OFFCORE_RESPONSE_0_MASK_ANY_IFETCH = (1ULL << 6 | 1ULL << 2 | 1ULL << 9)  << 8, // Request: combination of PF_IFETCH | DMND_IFETCH | UC_IFETCH
		OFFCORE_RESPONSE_0_MASK_ANY_REQUEST = 0xffff00, // Request: combination of all request umasks
		OFFCORE_RESPONSE_0_MASK_ANY_DATA = (1ULL << 0 | 1ULL << 4 | 1ULL << 13) << 8, // Request: combination of DMND_DATA | PF_L1_DATA_RD | PF_L2_DATA_RD
		OFFCORE_RESPONSE_0_MASK_ANY_RFO = (1ULL << 1 | 1ULL << 5) << 8, // Request: combination of DMND_RFO | PF_RFO
		OFFCORE_RESPONSE_0_MASK_ANY_RESPONSE = 1ULL << (16+8), // Response: count any response type
		OFFCORE_RESPONSE_0_MASK_L2_HIT = 1ULL << (18+8), // Supplier: counts L2 hits in M/E/S states
		OFFCORE_RESPONSE_0_MASK_SNP_NONE = 1ULL << (31+8), // Snoop: counts number of times no snoop-related information is available
		OFFCORE_RESPONSE_0_MASK_SNP_MISS = 1ULL << (33+8), // Snoop: counts number of times a snoop was needed and it missed all snooped caches
		OFFCORE_RESPONSE_0_MASK_SNP_HIT = 1ULL << (34+8), // Snoop: counts number of times a snoop hits in the other module where no modified copies were found in the L1 cache of the other core
		OFFCORE_RESPONSE_0_MASK_SNP_HITM = 1ULL << (36+8), // Snoop: counts number of times a snoop hits in the other module where modified copies were found in the L1 cache of the other core
		OFFCORE_RESPONSE_0_MASK_NON_DRAM = 1ULL << (37+8), // Snoop:  counts number of times target was a non-DRAM system address. This includes MMIO transactions
		OFFCORE_RESPONSE_0_MASK_SNP_ANY = 0x7dULL << (31+8), // Snoop: any snoop reason
		OFFCORE_RESPONSE_1 = 0x02b7, // Offcore response event (must provide at least one request type and either any_response or any combination of supplier + snoop)
		OFFCORE_RESPONSE_1_MASK_DMND_DATA_RD = 1ULL << (0 + 8), // Request: number of demand and DCU prefetch data reads of full and partial cachelines as well as demand data page table entry cacheline reads. Does not count L2 data read prefetches or instruction fetches
		OFFCORE_RESPONSE_1_MASK_DMND_RFO = 1ULL << (1 + 8), // Request: number of demand and DCU prefetch reads for ownership (RFO) requests generated by a write to data cacheline. Does not count L2 RFO prefetches
		OFFCORE_RESPONSE_1_MASK_DMND_IFETCH = 1ULL << (2 + 8), // Request: number of demand and DCU prefetch instruction cacheline reads. Does not count L2 code read prefetches
		OFFCORE_RESPONSE_1_MASK_WB = 1ULL << (3 + 8), // Request: number of writebacks (modified to exclusive) transactions
		OFFCORE_RESPONSE_1_MASK_PF_L2_DATA_RD = 1ULL << (4 + 8), // Request: number of data cacheline reads generated by L2 prefetchers
		OFFCORE_RESPONSE_1_MASK_PF_RFO = 1ULL << (5 + 8), // Request: number of RFO requests generated by L2 prefetchers
		OFFCORE_RESPONSE_1_MASK_PF_IFETCH = 1ULL << (6 + 8), // Request: number of code reads generated by L2 prefetchers
		OFFCORE_RESPONSE_1_MASK_PARTIAL_READ = 1ULL << (7 + 8), // Request: number of demand reads of partial cachelines (including UC
		OFFCORE_RESPONSE_1_MASK_PARTIAL_WRITE = 1ULL << (8 + 8), // Request: number of demand RFO requests to write to partial cache lines (includes UC
		OFFCORE_RESPONSE_1_MASK_UC_IFETCH = 1ULL << (9 + 8), // Request: number of UC instruction fetches
		OFFCORE_RESPONSE_1_MASK_BUS_LOCKS = 1ULL << (10 + 8), // Request: number bus lock and split lock requests
		OFFCORE_RESPONSE_1_MASK_STRM_ST = 1ULL << (11 + 8), // Request: number of streaming store requests
		OFFCORE_RESPONSE_1_MASK_SW_PREFETCH = 1ULL << (12 + 8), // Request: number of software prefetch requests
		OFFCORE_RESPONSE_1_MASK_PF_L1_DATA_RD = 1ULL << (13 + 8), // Request: number of data cacheline reads generated by L1 prefetchers
		OFFCORE_RESPONSE_1_MASK_PARTIAL_STRM_ST = 1ULL << (14 + 8), // Request: number of partial streaming store requests
		OFFCORE_RESPONSE_1_MASK_OTHER = 1ULL << (15+8), // Request: counts one any other request that crosses IDI
		OFFCORE_RESPONSE_1_MASK_ANY_IFETCH = (1ULL << 6 | 1ULL << 2 | 1ULL << 9)  << 8, // Request: combination of PF_IFETCH | DMND_IFETCH | UC_IFETCH
		OFFCORE_RESPONSE_1_MASK_ANY_REQUEST = 0xffff00, // Request: combination of all request umasks
		OFFCORE_RESPONSE_1_MASK_ANY_DATA = (1ULL << 0 | 1ULL << 4 | 1ULL << 13) << 8, // Request: combination of DMND_DATA | PF_L1_DATA_RD | PF_L2_DATA_RD
		OFFCORE_RESPONSE_1_MASK_ANY_RFO = (1ULL << 1 | 1ULL << 5) << 8, // Request: combination of DMND_RFO | PF_RFO
		OFFCORE_RESPONSE_1_MASK_ANY_RESPONSE = 1ULL << (16+8), // Response: count any response type
		OFFCORE_RESPONSE_1_MASK_L2_HIT = 1ULL << (18+8), // Supplier: counts L2 hits in M/E/S states
		OFFCORE_RESPONSE_1_MASK_SNP_NONE = 1ULL << (31+8), // Snoop: counts number of times no snoop-related information is available
		OFFCORE_RESPONSE_1_MASK_SNP_MISS = 1ULL << (33+8), // Snoop: counts number of times a snoop was needed and it missed all snooped caches
		OFFCORE_RESPONSE_1_MASK_SNP_HIT = 1ULL << (34+8), // Snoop: counts number of times a snoop hits in the other module where no modified copies were found in the L1 cache of the other core
		OFFCORE_RESPONSE_1_MASK_SNP_HITM = 1ULL << (36+8), // Snoop: counts number of times a snoop hits in the other module where modified copies were found in the L1 cache of the other core
		OFFCORE_RESPONSE_1_MASK_NON_DRAM = 1ULL << (37+8), // Snoop:  counts number of times target was a non-DRAM system address. This includes MMIO transactions
		OFFCORE_RESPONSE_1_MASK_SNP_ANY = 0x7dULL << (31+8), // Snoop: any snoop reason
		
	};
};