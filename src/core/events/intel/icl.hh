#include <cstdint>
#include <intel_priv.hh>
namespace optkit::intel::icl{
	enum icl : uint64_t {
		UNHALTED_CORE_CYCLES = 0x3c, // Count core clock cycles whenever the clock signal on the specific core is running (not halted)
		UNHALTED_REFERENCE_CYCLES = 0x0300, // Unhalted reference cycles
		INSTRUCTION_RETIRED = 0xc0, // Number of instructions at retirement
		INSTRUCTIONS_RETIRED = 0xc0, // Number of instructions at retirement
		SQ_MISC = 0x00f4, // SuperQueue miscellaneous.
		SQ_MISC__MASK__INTEL_ICL_SQ_MISC__SQ_FULL = 0x0400ull, // Cycles the thread is active and superQ cannot take any more entries.
		SQ_MISC__MASK__INTEL_ICL_SQ_MISC__BUS_LOCK = 0x1000ull, // Counts bus locks
		L2_LINES_OUT = 0x00f2, // L2 lines evicted.
		L2_LINES_OUT__MASK__INTEL_ICL_L2_LINES_OUT__USELESS_HWPF = 0x0400ull, // Cache lines that have been L2 hardware prefetched but not used by demand accesses
		L2_LINES_OUT__MASK__INTEL_ICL_L2_LINES_OUT__NON_SILENT = 0x0200ull, // Modified cache lines that are evicted by L2 cache when triggered by an L2 cache fill.
		L2_LINES_OUT__MASK__INTEL_ICL_L2_LINES_OUT__SILENT = 0x0100ull, // Non-modified cache lines that are silently dropped by L2 cache when triggered by an L2 cache fill.
		L2_LINES_IN = 0x00f1, // L2 lines allocated.
		L2_LINES_IN__MASK__INTEL_ICL_L2_LINES_IN__ALL = 0x1f00ull, // L2 cache lines filling L2
		L2_TRANS = 0x00f0, // L2 transactions.
		L2_TRANS__MASK__INTEL_ICL_L2_TRANS__L2_WB = 0x4000ull, // L2 writebacks that access L2 cache
		BACLEARS = 0x00e6, // Branch re-steers.
		BACLEARS__MASK__INTEL_ICL_BACLEARS__ANY = 0x0100ull, // Counts the total number when the front end is resteered
		MEM_LOAD_L3_HIT_RETIRED = 0x00d2, // L3 hit load uops retired.
		MEM_LOAD_L3_HIT_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_HIT_RETIRED__XSNP_NONE = 0x0800ull, // Retired load instructions whose data sources were hits in L3 without snoops required
		MEM_LOAD_L3_HIT_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_HIT_RETIRED__XSNP_HITM = 0x0400ull, // Retired load instructions whose data sources were HitM responses from shared L3
		MEM_LOAD_L3_HIT_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_HIT_RETIRED__XSNP_HIT = 0x0200ull, // Retired load instructions whose data sources were L3 and cross-core snoop hits in on-pkg core cache
		MEM_LOAD_L3_HIT_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_HIT_RETIRED__XSNP_MISS = 0x0100ull, // Retired load instructions whose data sources were L3 hit and cross-core snoop missed in on-pkg core cache.
		MEM_LOAD_RETIRED = 0x00d1, // Retired load uops.
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__FB_HIT = 0x4000ull, // Number of completed demand load requests that missed the L1
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__L3_MISS = 0x2000ull, // Retired load instructions missed L3 cache as data sources
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__L2_MISS = 0x1000ull, // Retired load instructions missed L2 cache as data sources
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__L1_MISS = 0x0800ull, // Retired load instructions missed L1 cache as data sources
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__L3_HIT = 0x0400ull, // Retired load instructions with L3 cache hits as data sources
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__L2_HIT = 0x0200ull, // Retired load instructions with L2 cache hits as data sources
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__L1_HIT = 0x0100ull, // Retired load instructions with L1 cache hits as data sources
		MEM_LOAD_RETIRED__MASK__INTEL_ICL_MEM_LOAD_RETIRED__LOCAL_PMM = 0x8000ull, // Retired load instructions with local Intel Optane DC persistent memory as the data source where the data request missed all caches.
		MEM_INST_RETIRED = 0x00d0, // Memory instructions retired.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__ALL_STORES = 0x8200ull, // All retired store instructions.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__ALL_LOADS = 0x8100ull, // All retired load instructions.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__SPLIT_STORES = 0x4200ull, // Retired store instructions that split across a cacheline boundary.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__SPLIT_LOADS = 0x4100ull, // Retired load instructions that split across a cacheline boundary.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__LOCK_LOADS = 0x2100ull, // Retired load instructions with locked access.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__STLB_MISS_STORES = 0x1200ull, // Retired store instructions that miss the STLB.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__STLB_MISS_LOADS = 0x1100ull, // Retired load instructions that miss the STLB.
		MEM_INST_RETIRED__MASK__INTEL_ICL_MEM_INST_RETIRED__ANY = 0x8300ull, // All retired memory instructions.
		MEM_LOAD_L3_MISS_RETIRED = 0x00d3, // Retired load instructions which data sources missed L3 but serviced from local dram
		MEM_LOAD_L3_MISS_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_MISS_RETIRED__REMOTE_PMM = 0x1000ull, // Retired load instructions with remote Intel Optane DC persistent memory as the data source where the data request missed all caches.
		MEM_LOAD_L3_MISS_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_MISS_RETIRED__REMOTE_FWD = 0x0800ull, // Retired load instructions whose data sources was forwarded from a remote cache
		MEM_LOAD_L3_MISS_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_MISS_RETIRED__REMOTE_HITM = 0x0400ull, // Retired load instructions whose data sources was remote HITM
		MEM_LOAD_L3_MISS_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_MISS_RETIRED__REMOTE_DRAM = 0x0200ull, // Retired load instructions which data sources missed L3 but serviced from remote dram
		MEM_LOAD_L3_MISS_RETIRED__MASK__INTEL_ICL_MEM_LOAD_L3_MISS_RETIRED__LOCAL_DRAM = 0x0100ull, // Retired load instructions which data sources missed L3 but serviced from local dram
		MEM_TRANS_RETIRED = 0x00cd, // Memory transactions retired
		MEM_TRANS_RETIRED__MASK__INTEL_ICL_MEM_TRANS_RETIRED__LOAD_LATENCY = 0x100, // Memory load instructions retired above programmed clocks
		MISC_RETIRED = 0x00cc, // Miscellaneous retired events.
		MISC_RETIRED__MASK__INTEL_ICL_MISC_RETIRED__PAUSE_INST = 0x4000ull, // Number of retired PAUSE instructions.
		MISC_RETIRED__MASK__INTEL_ICL_MISC_RETIRED__LBR_INSERTS = 0x2000ull, // Increments whenever there is an update to the LBR array.
		RTM_RETIRED = 0x00c9, // RTM (Restricted Transaction Memory) execution.
		RTM_RETIRED__MASK__INTEL_ICL_RTM_RETIRED__ABORTED_EVENTS = 0x8000ull, // Number of times an RTM execution aborted due to none of the previous 4 categories (e.g. interrupt)
		RTM_RETIRED__MASK__INTEL_ICL_RTM_RETIRED__ABORTED_MEMTYPE = 0x4000ull, // Number of times an RTM execution aborted due to incompatible memory type
		RTM_RETIRED__MASK__INTEL_ICL_RTM_RETIRED__ABORTED_UNFRIENDLY = 0x2000ull, // Number of times an RTM execution aborted due to HLE-unfriendly instructions
		RTM_RETIRED__MASK__INTEL_ICL_RTM_RETIRED__ABORTED_MEM = 0x0800ull, // Number of times an RTM execution aborted due to various memory events (e.g. read/write capacity and conflicts)
		RTM_RETIRED__MASK__INTEL_ICL_RTM_RETIRED__ABORTED = 0x0400ull, // Number of times an RTM execution aborted.
		RTM_RETIRED__MASK__INTEL_ICL_RTM_RETIRED__COMMIT = 0x0200ull, // Number of times an RTM execution successfully committed
		RTM_RETIRED__MASK__INTEL_ICL_RTM_RETIRED__START = 0x0100ull, // Number of times an RTM execution started.
		HLE_RETIRED = 0x00c8, // HLE (Hardware Lock Elision) execution.
		HLE_RETIRED__MASK__INTEL_ICL_HLE_RETIRED__ABORTED_EVENTS = 0x8000ull, // Number of times an HLE execution aborted due to unfriendly events (such as interrupts).
		HLE_RETIRED__MASK__INTEL_ICL_HLE_RETIRED__ABORTED_UNFRIENDLY = 0x2000ull, // Number of times an HLE execution aborted due to HLE-unfriendly instructions and certain unfriendly events (such as AD assists etc.).
		HLE_RETIRED__MASK__INTEL_ICL_HLE_RETIRED__ABORTED_MEM = 0x0800ull, // Number of times an HLE execution aborted due to various memory events (e.g.
		HLE_RETIRED__MASK__INTEL_ICL_HLE_RETIRED__ABORTED = 0x0400ull, // Number of times an HLE execution aborted due to any reasons (multiple categories may count as one).
		HLE_RETIRED__MASK__INTEL_ICL_HLE_RETIRED__COMMIT = 0x0200ull, // Number of times an HLE execution successfully committed
		HLE_RETIRED__MASK__INTEL_ICL_HLE_RETIRED__START = 0x0100ull, // Number of times an HLE execution started.
		FP_ARITH_INST_RETIRED = 0x00c7, // Floating-point instructions retired.
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__512B_PACKED_SINGLE = 0x8000ull, // Counts number of SSE/AVX computational 512-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 16 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__512B_PACKED_DOUBLE = 0x4000ull, // Counts number of SSE/AVX computational 512-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__256B_PACKED_SINGLE = 0x2000ull, // Counts number of SSE/AVX computational 256-bit packed single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__256B_PACKED_DOUBLE = 0x1000ull, // Counts number of SSE/AVX computational 256-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 4 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__128B_PACKED_SINGLE = 0x0800ull, // Number of SSE/AVX computational 128-bit packed single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 4 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__128B_PACKED_DOUBLE = 0x0400ull, // Counts number of SSE/AVX computational 128-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 2 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__SCALAR_SINGLE = 0x0200ull, // Counts number of SSE/AVX computational scalar single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 1 computational operation. Applies to SSE* and AVX* scalar single precision floating-point instructions: ADD SUB MUL DIV MIN MAX SQRT RSQRT RCP FM(N)ADD/SUB.  FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element. The DAZ and FTZ flags in the MXCSR register need to be set when using this event.
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__SCALAR_DOUBLE = 0x0100ull, // Counts number of SSE/AVX computational scalar double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 1 computational operation. Applies to SSE* and AVX* scalar double precision floating-point instructions: ADD SUB MUL DIV MIN MAX SQRT FM(N)ADD/SUB.  FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element. The DAZ and FTZ flags in the MXCSR register need to be set when using this event.
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__SCALAR = 0x0300ull, // Number of SSE/AVX computational scalar floating-point instructions retired; some instructions will count twice as noted below.  Applies to SSE* and AVX* scalar
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__4_FLOPS = 0x1800ull, // Number of SSE/AVX computational 128-bit packed single and 256-bit packed double precision FP instructions retired; some instructions will count twice as noted below.  Each count represents 2 or/and 4 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__8_FLOPS = 0x6000ull, // Number of SSE/AVX computational 256-bit packed single precision and 512-bit packed double precision  FP instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations
		FP_ARITH_INST_RETIRED__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__VECTOR = 0xfc00ull, // Number of any Vector retired FP arithmetic instructions
		FP_ARITH = 0x00c7, // Floating-point instructions retired.
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__512B_PACKED_SINGLE = 0x8000ull, // Counts number of SSE/AVX computational 512-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 16 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__512B_PACKED_DOUBLE = 0x4000ull, // Counts number of SSE/AVX computational 512-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__256B_PACKED_SINGLE = 0x2000ull, // Counts number of SSE/AVX computational 256-bit packed single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__256B_PACKED_DOUBLE = 0x1000ull, // Counts number of SSE/AVX computational 256-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 4 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__128B_PACKED_SINGLE = 0x0800ull, // Number of SSE/AVX computational 128-bit packed single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 4 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__128B_PACKED_DOUBLE = 0x0400ull, // Counts number of SSE/AVX computational 128-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 2 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__SCALAR_SINGLE = 0x0200ull, // Counts number of SSE/AVX computational scalar single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 1 computational operation. Applies to SSE* and AVX* scalar single precision floating-point instructions: ADD SUB MUL DIV MIN MAX SQRT RSQRT RCP FM(N)ADD/SUB.  FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element. The DAZ and FTZ flags in the MXCSR register need to be set when using this event.
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__SCALAR_DOUBLE = 0x0100ull, // Counts number of SSE/AVX computational scalar double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 1 computational operation. Applies to SSE* and AVX* scalar double precision floating-point instructions: ADD SUB MUL DIV MIN MAX SQRT FM(N)ADD/SUB.  FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element. The DAZ and FTZ flags in the MXCSR register need to be set when using this event.
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__SCALAR = 0x0300ull, // Number of SSE/AVX computational scalar floating-point instructions retired; some instructions will count twice as noted below.  Applies to SSE* and AVX* scalar
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__4_FLOPS = 0x1800ull, // Number of SSE/AVX computational 128-bit packed single and 256-bit packed double precision FP instructions retired; some instructions will count twice as noted below.  Each count represents 2 or/and 4 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__8_FLOPS = 0x6000ull, // Number of SSE/AVX computational 256-bit packed single precision and 512-bit packed double precision  FP instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations
		FP_ARITH__MASK__INTEL_ICL_FP_ARITH_INST_RETIRED__VECTOR = 0xfc00ull, // Number of any Vector retired FP arithmetic instructions
		FRONTEND_RETIRED = 0x01c6, // Precise frontend retired events.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_1 = 0x50010600ull, // Retired instructions after front-end starvation of at least 1 cycle
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_2_BUBBLES_GE_1 = 0x10020600ull, // Retired instructions that are fetched after an interval where the front-end had at least 1 bubble-slot for a period of 2 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_512 = 0x52000600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 512 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_256 = 0x51000600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 256 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_128 = 0x50800600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 128 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_64 = 0x50400600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 64 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_32 = 0x50200600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 32 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_16 = 0x50100600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 16 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_8 = 0x50080600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 8 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_4 = 0x50040600ull, // Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 4 cycles which was not interrupted by a back-end stall.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__LATENCY_GE_2 = 0x50020600ull, // Retired instructions after front-end starvation of at least 2 cycles
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__STLB_MISS = 0x1500ull, // Retired Instructions who experienced STLB (2nd level TLB) true miss.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__ITLB_MISS = 0x1400ull, // Retired Instructions who experienced iTLB true miss.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__L2_MISS = 0x1300ull, // Retired Instructions who experienced Instruction L2 Cache true miss.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__L1I_MISS = 0x1200ull, // Retired Instructions who experienced Instruction L1 Cache true miss.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__DSB_MISS = 0x1100ull, // Retired Instructions experiencing a critical DSB miss.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__ANY_DSB_MISS = 0x0100ull, // Retired Instructions experiencing a DSB miss.
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__IDQ_4_BUBBLES = (4 << 20 | 0x6) << 8, // Retired instructions after an interval where the front-end did not deliver any uops (4 bubbles) for a period determined by the fe_thres modifier (set to 1 cycle by default) and which was not interrupted by a back-end stall
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__IDQ_3_BUBBLES = (3 << 20 | 0x6) << 8, // Counts instructions retired after an interval where the front-end did not deliver more than 1 uop (3 bubbles) for a period determined by the fe_thres modifier (set to 1 cycle by default) and which was not interrupted by a back-end stall
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__IDQ_2_BUBBLES = (2 << 20 | 0x6) << 8, // Counts instructions retired after an interval where the front-end did not deliver more than 2 uops (2 bubbles) for a period determined by the fe_thres modifier (set to 1 cycle by default) and which was not interrupted by a back-end stall
		FRONTEND_RETIRED__MASK__INTEL_ICL_FRONTEND_RETIRED__IDQ_1_BUBBLE = (1 << 20 | 0x6) << 8, // Counts instructions retired after an interval where the front-end did not deliver more than 3 uops (1 bubble) for a period determined by the fe_thres modifier (set to 1 cycle by default) and which was not interrupted by a back-end stall
		BR_MISP_RETIRED = 0x00c5, // Mispredicted branch instructions retired.
		BR_MISP_RETIRED__MASK__INTEL_ICL_BR_MISP_RETIRED__INDIRECT = 0x8000ull, // All miss-predicted indirect branch instructions retired (excluding RETs. TSX aborts is considered indirect branch).
		BR_MISP_RETIRED__MASK__INTEL_ICL_BR_MISP_RETIRED__NEAR_TAKEN = 0x2000ull, // Number of near branch instructions retired that were mispredicted and taken.
		BR_MISP_RETIRED__MASK__INTEL_ICL_BR_MISP_RETIRED__COND = 0x1100ull, // Mispredicted conditional branch instructions retired.
		BR_MISP_RETIRED__MASK__INTEL_ICL_BR_MISP_RETIRED__COND_NTAKEN = 0x1000ull, // Mispredicted non-taken conditional branch instructions retired.
		BR_MISP_RETIRED__MASK__INTEL_ICL_BR_MISP_RETIRED__INDIRECT_CALL = 0x0200ull, // Mispredicted indirect CALL instructions retired.
		BR_MISP_RETIRED__MASK__INTEL_ICL_BR_MISP_RETIRED__COND_TAKEN = 0x0100ull, // number of branch instructions retired that were mispredicted and taken.
		BR_MISP_RETIRED__MASK__INTEL_ICL_BR_MISP_RETIRED__ALL_BRANCHES = 0x0000ull, // All mispredicted branch instructions retired.
		BR_INST_RETIRED = 0x00c4, // Branch instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__INDIRECT = 0x8000ull, // Indirect near branch instructions retired (excluding returns)
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__FAR_BRANCH = 0x4000ull, // Far branch instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__NEAR_TAKEN = 0x2000ull, // Taken branch instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__COND = 0x1100ull, // Conditional branch instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__COND_NTAKEN = 0x1000ull, // Not taken branch instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__NEAR_RETURN = 0x0800ull, // Return instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__NEAR_CALL = 0x0200ull, // Direct and indirect near call instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__COND_TAKEN = 0x0100ull, // Taken conditional branch instructions retired.
		BR_INST_RETIRED__MASK__INTEL_ICL_BR_INST_RETIRED__ALL_BRANCHES = 0x0000ull, // All branch instructions retired.
		MACHINE_CLEARS = 0x00c3, // Machine clear asserted.
		MACHINE_CLEARS__MASK__INTEL_ICL_MACHINE_CLEARS__SMC = 0x0400ull, // Self-modifying code (SMC) detected.
		MACHINE_CLEARS__MASK__INTEL_ICL_MACHINE_CLEARS__MEMORY_ORDERING = 0x0200ull, // Number of machine clears due to memory ordering conflicts.
		MACHINE_CLEARS__MASK__INTEL_ICL_MACHINE_CLEARS__COUNT = 0x0100ull | (0x1 << INTEL_X86_CMASK_BIT) | (0x1 << INTEL_X86_EDGE_BIT), // Number of machine clears (nukes) of any type.
		UOPS_RETIRED = 0x00c2, // Retired uops.
		UOPS_RETIRED__MASK__INTEL_ICL_UOPS_RETIRED__SLOTS = 0x0200ull, // Retirement slots used.
		UOPS_RETIRED__MASK__INTEL_ICL_UOPS_RETIRED__TOTAL_CYCLES = 0x0200ull | (0x1 << INTEL_X86_INV_BIT) | (0xa << INTEL_X86_CMASK_BIT), // Cycles with less than 10 actually retired uops.
		UOPS_RETIRED__MASK__INTEL_ICL_UOPS_RETIRED__STALL_CYCLES = 0x0200ull | (0x1 << INTEL_X86_INV_BIT) | (0x1 << INTEL_X86_CMASK_BIT), // Cycles without actually retired uops.
		ASSISTS = 0x00c1, // Software assist.
		ASSISTS__MASK__INTEL_ICL_ASSISTS__ANY = 0x0700ull, // Number of occurrences where a microcode assist is invoked by hardware.
		ASSISTS__MASK__INTEL_ICL_ASSISTS__FP = 0x0200ull, // Counts all microcode FP assists.
		TLB_FLUSH = 0x00bd, // Data TLB flushes.
		TLB_FLUSH__MASK__INTEL_ICL_TLB_FLUSH__STLB_ANY = 0x2000ull, // STLB flush attempts
		TLB_FLUSH__MASK__INTEL_ICL_TLB_FLUSH__DTLB_THREAD = 0x0100ull, // DTLB flush attempts of the thread-specific entries
		UOPS_EXECUTED = 0x00b1, // Uops executed.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__X87 = 0x1000ull, // Counts the number of x87 uops dispatched.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CORE_CYCLES_GE_4 = 0x0200ull | (0x4 << INTEL_X86_CMASK_BIT), // Cycles at least 4 micro-op is executed from any thread on physical core.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CORE_CYCLES_GE_3 = 0x0200ull | (0x3 << INTEL_X86_CMASK_BIT), // Cycles at least 3 micro-op is executed from any thread on physical core.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CORE_CYCLES_GE_2 = 0x0200ull | (0x2 << INTEL_X86_CMASK_BIT), // Cycles at least 2 micro-op is executed from any thread on physical core.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CORE_CYCLES_GE_1 = 0x0200ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles at least 1 micro-op is executed from any thread on physical core.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CORE = 0x0200ull, // Number of uops executed on the core.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CYCLES_GE_4 = 0x0100ull | (0x4 << INTEL_X86_CMASK_BIT), // Cycles where at least 4 uops were executed per-thread
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CYCLES_GE_3 = 0x0100ull | (0x3 << INTEL_X86_CMASK_BIT), // Cycles where at least 3 uops were executed per-thread
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CYCLES_GE_2 = 0x0100ull | (0x2 << INTEL_X86_CMASK_BIT), // Cycles where at least 2 uops were executed per-thread
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__CYCLES_GE_1 = 0x0100ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles where at least 1 uop was executed per-thread
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__STALL_CYCLES = 0x0100ull | (0x1 << INTEL_X86_INV_BIT) | (0x1 << INTEL_X86_CMASK_BIT), // Counts number of cycles no uops were dispatched to be executed on this thread.
		UOPS_EXECUTED__MASK__INTEL_ICL_UOPS_EXECUTED__THREAD = 0x0100ull, // Counts the number of uops to be executed per-thread each cycle.
		OFFCORE_REQUESTS = 0x00b0, // Requests sent to uncore.
		OFFCORE_REQUESTS__MASK__INTEL_ICL_OFFCORE_REQUESTS__ALL_REQUESTS = 0x8000ull, // Any memory transaction that reached the SQ.
		OFFCORE_REQUESTS__MASK__INTEL_ICL_OFFCORE_REQUESTS__L3_MISS_DEMAND_DATA_RD = 0x1000ull, // Demand Data Read requests who miss L3 cache
		OFFCORE_REQUESTS__MASK__INTEL_ICL_OFFCORE_REQUESTS__ALL_DATA_RD = 0x0800ull, // Demand and prefetch data reads
		OFFCORE_REQUESTS__MASK__INTEL_ICL_OFFCORE_REQUESTS__DEMAND_RFO = 0x0400ull, // Demand RFO requests including regular RFOs
		OFFCORE_REQUESTS__MASK__INTEL_ICL_OFFCORE_REQUESTS__DEMAND_DATA_RD = 0x0100ull, // Demand Data Read requests sent to uncore
		OFFCORE_REQUESTS__MASK__INTEL_ICL_OFFCORE_REQUESTS__DEMAND_CODE_RD = 0x0200ull, // Counts cacheable and non-cacheable code reads to the core.
		DSB2MITE_SWITCHES = 0x00ab, // Number of DSB to MITE switches.
		DSB2MITE_SWITCHES__MASK__INTEL_ICL_DSB2MITE_SWITCHES__COUNT = 0x0200ull | (0x1 << INTEL_X86_CMASK_BIT) | (0x1 << INTEL_X86_EDGE_BIT), // DSB-to-MITE transitions count.
		DSB2MITE_SWITCHES__MASK__INTEL_ICL_DSB2MITE_SWITCHES__PENALTY_CYCLES = 0x0200ull, // DSB-to-MITE switch true penalty cycles.
		LSD = 0x00a8, // LSD (Loop stream detector) operations.
		LSD__MASK__INTEL_ICL_LSD__CYCLES_OK = 0x0100ull | (0x5 << INTEL_X86_CMASK_BIT), // Cycles optimal number of Uops delivered by the LSD
		LSD__MASK__INTEL_ICL_LSD__CYCLES_ACTIVE = 0x0100ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles Uops delivered by the LSD
		LSD__MASK__INTEL_ICL_LSD__UOPS = 0x0100ull, // Number of Uops delivered by the LSD.
		EXE_ACTIVITY = 0x00a6, // Execution activity
		EXE_ACTIVITY__MASK__INTEL_ICL_EXE_ACTIVITY__EXE_BOUND_0_PORTS = 0x8000ull, // Cycles where no uops were executed
		EXE_ACTIVITY__MASK__INTEL_ICL_EXE_ACTIVITY__BOUND_ON_STORES = 0x4000ull | (0x2 << INTEL_X86_CMASK_BIT), // Cycles where the Store Buffer was full and no loads caused an execution stall.
		EXE_ACTIVITY__MASK__INTEL_ICL_EXE_ACTIVITY__4_PORTS_UTIL = 0x1000ull, // Cycles total of 4 uops are executed on all ports and Reservation Station was not empty.
		EXE_ACTIVITY__MASK__INTEL_ICL_EXE_ACTIVITY__3_PORTS_UTIL = 0x0800ull, // Cycles total of 3 uops are executed on all ports and Reservation Station was not empty.
		EXE_ACTIVITY__MASK__INTEL_ICL_EXE_ACTIVITY__2_PORTS_UTIL = 0x0400ull, // Cycles total of 2 uops are executed on all ports and Reservation Station was not empty.
		EXE_ACTIVITY__MASK__INTEL_ICL_EXE_ACTIVITY__1_PORTS_UTIL = 0x0200ull, // Cycles total of 1 uop is executed on all ports and Reservation Station was not empty.
		CYCLE_ACTIVITY = 0x00a3, // Stalled cycles.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__STALLS_MEM_ANY = 0x1400ull | (0x14 << INTEL_X86_CMASK_BIT), // Execution stalls while memory subsystem has an outstanding load.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__CYCLES_MEM_ANY = 0x1000ull | (0x10 << INTEL_X86_CMASK_BIT), // Cycles while memory subsystem has an outstanding load.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__STALLS_L1D_MISS = 0x0c00ull | (0xc << INTEL_X86_CMASK_BIT), // Execution stalls while L1 cache miss demand load is outstanding.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__CYCLES_L1D_MISS = 0x0800ull | (0x8 << INTEL_X86_CMASK_BIT), // Cycles while L1 cache miss demand load is outstanding.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__STALLS_L3_MISS = 0x0600ull | (0x6 << INTEL_X86_CMASK_BIT), // Execution stalls while L3 cache miss demand load is outstanding.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__STALLS_L2_MISS = 0x0500ull | (0x5 << INTEL_X86_CMASK_BIT), // Execution stalls while L2 cache miss demand load is outstanding.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__STALLS_TOTAL = 0x0400ull | (0x4 << INTEL_X86_CMASK_BIT), // Total execution stalls.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__CYCLES_L3_MISS = 0x0200ull | (0x2 << INTEL_X86_CMASK_BIT), // Cycles while L3 cache miss demand load is outstanding.
		CYCLE_ACTIVITY__MASK__INTEL_ICL_CYCLE_ACTIVITY__CYCLES_L2_MISS = 0x0100ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles while L2 cache miss demand load is outstanding.
		RESOURCE_STALLS = 0x00a2, // Cycles where Allocation is stalled due to Resource Related reasons.
		RESOURCE_STALLS__MASK__INTEL_ICL_RESOURCE_STALLS__SB = 0x0800ull, // Cycles stalled due to no store buffers available. (not including draining form sync).
		RESOURCE_STALLS__MASK__INTEL_ICL_RESOURCE_STALLS__SCOREBOARD = 0x0200ull, // Counts cycles where the pipeline is stalled due to serializing operations.
		UOPS_DISPATCHED = 0x00a1, // Uops dispatched to specific ports
		UOPS_DISPATCHED__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_7_8 = 0x8000ull, // Number of uops executed on port 7 and 8
		UOPS_DISPATCHED__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_6 = 0x4000ull, // Number of uops executed on port 6
		UOPS_DISPATCHED__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_5 = 0x2000ull, // Number of uops executed on port 5
		UOPS_DISPATCHED__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_4_9 = 0x1000ull, // Number of uops executed on port 4 and 9
		UOPS_DISPATCHED__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_2_3 = 0x0400ull, // Number of uops executed on port 2 and 3
		UOPS_DISPATCHED__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_1 = 0x0200ull, // Number of uops executed on port 1
		UOPS_DISPATCHED__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_0 = 0x0100ull, // Number of uops executed on port 0
		UOPS_DISPATCHED_PORT = 0x00a1, // Uops dispatched to specific ports
		UOPS_DISPATCHED_PORT__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_7_8 = 0x8000ull, // Number of uops executed on port 7 and 8
		UOPS_DISPATCHED_PORT__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_6 = 0x4000ull, // Number of uops executed on port 6
		UOPS_DISPATCHED_PORT__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_5 = 0x2000ull, // Number of uops executed on port 5
		UOPS_DISPATCHED_PORT__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_4_9 = 0x1000ull, // Number of uops executed on port 4 and 9
		UOPS_DISPATCHED_PORT__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_2_3 = 0x0400ull, // Number of uops executed on port 2 and 3
		UOPS_DISPATCHED_PORT__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_1 = 0x0200ull, // Number of uops executed on port 1
		UOPS_DISPATCHED_PORT__MASK__INTEL_ICL_UOPS_DISPATCHED__PORT_0 = 0x0100ull, // Number of uops executed on port 0
		IDQ_UOPS_NOT_DELIVERED = 0x009c, // Uops not delivered.
		IDQ_UOPS_NOT_DELIVERED__MASK__INTEL_ICL_IDQ_UOPS_NOT_DELIVERED__CYCLES_FE_WAS_OK = 0x0100ull | (0x1 << INTEL_X86_INV_BIT) | (0x1 << INTEL_X86_CMASK_BIT), // Cycles when optimal number of uops was delivered to the back-end when the back-end is not stalled
		IDQ_UOPS_NOT_DELIVERED__MASK__INTEL_ICL_IDQ_UOPS_NOT_DELIVERED__CYCLES_0_UOPS_DELIV_CORE = 0x0100ull | (0x5 << INTEL_X86_CMASK_BIT), // Cycles when no uops are not delivered by the IDQ when backend of the machine is not stalled
		IDQ_UOPS_NOT_DELIVERED__MASK__INTEL_ICL_IDQ_UOPS_NOT_DELIVERED__CORE = 0x0100ull, // Uops not delivered by IDQ when backend of the machine is not stalled
		ILD_STALL = 0x0087, // ILD (Instruction Length Decoder) stalls.
		ILD_STALL__MASK__INTEL_ICL_ILD_STALL__LCP = 0x0100ull, // Stalls caused by changing prefix length of the instruction.
		ITLB_MISSES = 0x0085, // Instruction TLB misses.
		ITLB_MISSES__MASK__INTEL_ICL_ITLB_MISSES__STLB_HIT = 0x2000ull, // Instruction fetch requests that miss the ITLB and hit the STLB.
		ITLB_MISSES__MASK__INTEL_ICL_ITLB_MISSES__WALK_ACTIVE = 0x1000ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles when at least one PMH is busy with a page walk for code (instruction fetch) request.
		ITLB_MISSES__MASK__INTEL_ICL_ITLB_MISSES__WALK_PENDING = 0x1000ull, // Number of page walks outstanding for an outstanding code request in the PMH each cycle.
		ITLB_MISSES__MASK__INTEL_ICL_ITLB_MISSES__WALK_COMPLETED = 0x0e00ull, // Code miss in all TLB levels causes a page walk that completes. (All page sizes)
		ITLB_MISSES__MASK__INTEL_ICL_ITLB_MISSES__WALK_COMPLETED_2M_4M = 0x0400ull, // Code miss in all TLB levels causes a page walk that completes. (2M/4M)
		ITLB_MISSES__MASK__INTEL_ICL_ITLB_MISSES__WALK_COMPLETED_4K = 0x0200ull, // Code miss in all TLB levels causes a page walk that completes. (4K)
		ICACHE_64B = 0x0083, // Instruction Cache.
		ICACHE_64B__MASK__INTEL_ICL_ICACHE_64B__IFTAG_STALL = 0x0400ull, // Cycles where a code fetch is stalled due to L1 instruction cache tag miss.
		ICACHE_64B__MASK__INTEL_ICL_ICACHE_64B__IFTAG_MISS = 0x0200ull, // Instruction fetch tag lookups that miss in the instruction cache (L1I). Counts at 64-byte cache-line granularity.
		ICACHE_64B__MASK__INTEL_ICL_ICACHE_64B__IFTAG_HIT = 0x0100ull, // Instruction fetch tag lookups that hit in the instruction cache (L1I). Counts at 64-byte cache-line granularity.
		ICACHE_16B = 0x0080, // Instruction Cache.
		ICACHE_16B__MASK__INTEL_ICL_ICACHE_16B__IFDATA_STALL = 0x0400ull, // Cycles where a code fetch is stalled due to L1 instruction cache miss.
		IDQ = 0x0079, // IDQ (Instruction Decoded Queue) operations
		IDQ__MASK__INTEL_ICL_IDQ__MS_CYCLES_ANY = 0x3000ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles when uops are being delivered to IDQ while MS is busy
		IDQ__MASK__INTEL_ICL_IDQ__MS_UOPS = 0x3000ull, // Uops delivered to IDQ while MS is busy
		IDQ__MASK__INTEL_ICL_IDQ__MS_SWITCHES = 0x3000ull | (0x1 << INTEL_X86_CMASK_BIT) | (0x1 << INTEL_X86_EDGE_BIT), // Number of switches from DSB or MITE to the MS
		IDQ__MASK__INTEL_ICL_IDQ__DSB_CYCLES_ANY = 0x0800ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles Decode Stream Buffer (DSB) is delivering any Uop
		IDQ__MASK__INTEL_ICL_IDQ__DSB_CYCLES_OK = 0x0800ull | (0x5 << INTEL_X86_CMASK_BIT), // Cycles DSB is delivering optimal number of Uops
		IDQ__MASK__INTEL_ICL_IDQ__DSB_UOPS = 0x0800ull, // Uops delivered to Instruction Decode Queue (IDQ) from the Decode Stream Buffer (DSB) path
		IDQ__MASK__INTEL_ICL_IDQ__MITE_CYCLES_ANY = 0x0400ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles MITE is delivering any Uop
		IDQ__MASK__INTEL_ICL_IDQ__MITE_CYCLES_OK = 0x0400ull | (0x5 << INTEL_X86_CMASK_BIT), // Cycles MITE is delivering optimal number of Uops
		IDQ__MASK__INTEL_ICL_IDQ__MITE_UOPS = 0x0400ull, // Uops delivered to Instruction Decode Queue (IDQ) from MITE path
		OFFCORE_REQUESTS_OUTSTANDING = 0x0060, // Outstanding offcore requests.
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__DEMAND_DATA_RD = 0x0100ull, // For every cycle
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__DEMAND_CODE_RD = 0x0200ull, // For every cycle
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__CYCLES_WITH_DEMAND_CODE_RD = 0x0200ull |  (0x1 << INTEL_X86_CMASK_BIT), // Cycles with outstanding code read requests pending.
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__CYCLES_WITH_DEMAND_RFO = 0x0400ull |  (0x1 << INTEL_X86_CMASK_BIT), // Cycles where at least 1 outstanding Demand RFO request is pending.
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__ALL_DATA_RD = 0x0800ull, // For every cycle
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__CYCLES_WITH_DATA_RD = 0x0800ull |  (0x1 << INTEL_X86_CMASK_BIT), // Cycles where at least 1 outstanding data read request is pending.
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__L3_MISS_DEMAND_DATA_RD = 0x1000ull, // For every cycle
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__CYCLES_WITH_L3_MISS_DEMAND_DATA_RD = 0x1000ull |  (0x1 << INTEL_X86_CMASK_BIT), // Cycles where at least one demand data read request known to have missed the L3 cache is pending.
		OFFCORE_REQUESTS_OUTSTANDING__MASK__INTEL_ICL_OFFCORE_REQUESTS_OUTSTANDING__L3_MISS_DEMAND_DATA_RD_GE_6 = 0x1000ull |  (0x6 << INTEL_X86_CMASK_BIT), // Cycles where the core is waiting on at least 6 outstanding demand data read requests known to have missed the L3 cache.
		RS_EVENTS = 0x005e, // Reservation Station.
		RS_EVENTS__MASK__INTEL_ICL_RS_EVENTS__EMPTY_END = 0x0100ull | (0x1 << INTEL_X86_INV_BIT) | (0x1 << INTEL_X86_CMASK_BIT) | (0x1 << INTEL_X86_EDGE_BIT), // Counts end of periods where the Reservation Station (RS) was empty.
		RS_EVENTS__MASK__INTEL_ICL_RS_EVENTS__EMPTY_CYCLES = 0x0100ull, // Cycles when Reservation Station (RS) is empty for the thread
		TX_EXEC = 0x005d, // Transactional execution.
		TX_EXEC__MASK__INTEL_ICL_TX_EXEC__MISC3 = 0x0400ull, // Number of times an instruction execution caused the transactional nest count supported to be exceeded
		TX_EXEC__MASK__INTEL_ICL_TX_EXEC__MISC2 = 0x0200ull, // Counts the number of times a class of instructions that may cause a transactional abort was executed inside a transactional region
		TX_MEM = 0x0054, // Transactional memory.
		TX_MEM__MASK__INTEL_ICL_TX_MEM__ABORT_CAPACITY_READ = 0x8000ull, // Speculatively counts the number of TSX aborts due to a data capacity limitation for transactional reads
		TX_MEM__MASK__INTEL_ICL_TX_MEM__HLE_ELISION_BUFFER_FULL = 0x4000ull, // Number of times HLE lock could not be elided due to ElisionBufferAvailable being zero.
		TX_MEM__MASK__INTEL_ICL_TX_MEM__ABORT_HLE_ELISION_BUFFER_UNSUPPORTED_ALIGNMENT = 0x2000ull, // Number of times an HLE transactional execution aborted due to an unsupported read alignment from the elision buffer.
		TX_MEM__MASK__INTEL_ICL_TX_MEM__ABORT_HLE_ELISION_BUFFER_MISMATCH = 0x1000ull, // Number of times an HLE transactional execution aborted due to XRELEASE lock not satisfying the address and value requirements in the elision buffer
		TX_MEM__MASK__INTEL_ICL_TX_MEM__ABORT_HLE_ELISION_BUFFER_NOT_EMPTY = 0x0800ull, // Number of times an HLE transactional execution aborted due to NoAllocatedElisionBuffer being non-zero.
		TX_MEM__MASK__INTEL_ICL_TX_MEM__ABORT_HLE_STORE_TO_ELIDED_LOCK = 0x0400ull, // Number of times a HLE transactional region aborted due to a non XRELEASE prefixed instruction writing to an elided lock in the elision buffer
		TX_MEM__MASK__INTEL_ICL_TX_MEM__ABORT_CAPACITY_WRITE = 0x0200ull, // Speculatively counts the number of TSX aborts due to a data capacity limitation for transactional writes.
		TX_MEM__MASK__INTEL_ICL_TX_MEM__ABORT_CONFLICT = 0x0100ull, // Number of times a transactional abort was signaled due to a data conflict on a transactionally accessed address
		L1D = 0x0051, // L1D cache.
		L1D__MASK__INTEL_ICL_L1D__REPLACEMENT = 0x0100ull, // Counts the number of cache lines replaced in L1 data cache.
		LOAD_HIT_PREFETCH = 0x004c, // Load dispatches.
		LOAD_HIT_PREFETCH__MASK__INTEL_ICL_LOAD_HIT_PREFETCH__SWPF = 0x0100ull, // Counts the number of demand load dispatches that hit L1D fill buffer (FB) allocated for software prefetch.
		LOAD_HIT_PRE = 0x004c, // Load dispatches.
		LOAD_HIT_PRE__MASK__INTEL_ICL_LOAD_HIT_PREFETCH__SWPF = 0x0100ull, // Counts the number of demand load dispatches that hit L1D fill buffer (FB) allocated for software prefetch.
		DTLB_STORE_MISSES = 0x0049, // Data TLB store misses.
		DTLB_STORE_MISSES__MASK__INTEL_ICL_DTLB_STORE_MISSES__STLB_HIT = 0x2000ull, // Stores that miss the DTLB and hit the STLB.
		DTLB_STORE_MISSES__MASK__INTEL_ICL_DTLB_STORE_MISSES__WALK_ACTIVE = 0x1000ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles when at least one PMH is busy with a page walk for a store.
		DTLB_STORE_MISSES__MASK__INTEL_ICL_DTLB_STORE_MISSES__WALK_PENDING = 0x1000ull, // Number of page walks outstanding for a store in the PMH each cycle.
		DTLB_STORE_MISSES__MASK__INTEL_ICL_DTLB_STORE_MISSES__WALK_COMPLETED = 0x0e00ull, // Store misses in all TLB levels causes a page walk that completes. (All page sizes)
		DTLB_STORE_MISSES__MASK__INTEL_ICL_DTLB_STORE_MISSES__WALK_COMPLETED_2M_4M = 0x0400ull, // Page walks completed due to a demand data store to a 2M/4M page.
		DTLB_STORE_MISSES__MASK__INTEL_ICL_DTLB_STORE_MISSES__WALK_COMPLETED_4K = 0x0200ull, // Page walks completed due to a demand data store to a 4K page.
		L1D_PEND_MISS = 0x0048, // L1D pending misses.
		L1D_PEND_MISS__MASK__INTEL_ICL_L1D_PEND_MISS__L2_STALL = 0x0400ull, // Number of cycles a demand request has waited due to L1D due to lack of L2 resources.
		L1D_PEND_MISS__MASK__INTEL_ICL_L1D_PEND_MISS__FB_FULL_PERIODS = 0x0200ull | (0x1 << INTEL_X86_CMASK_BIT) | (0x1 << INTEL_X86_EDGE_BIT), // Number of phases a demand request has waited due to L1D Fill Buffer (FB) unavailability.
		L1D_PEND_MISS__MASK__INTEL_ICL_L1D_PEND_MISS__FB_FULL = 0x0200ull, // Number of cycles a demand request has waited due to L1D Fill Buffer (FB) unavailability.
		L1D_PEND_MISS__MASK__INTEL_ICL_L1D_PEND_MISS__PENDING_CYCLES = 0x0100ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles with L1D load Misses outstanding.
		L1D_PEND_MISS__MASK__INTEL_ICL_L1D_PEND_MISS__PENDING = 0x0100ull, // Number of L1D misses that are outstanding
		SW_PREFETCH_ACCESS = 0x0032, // Software prefetches.
		SW_PREFETCH_ACCESS__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__PREFETCHW = 0x0800ull, // Number of PREFETCHW instructions executed.
		SW_PREFETCH_ACCESS__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__T1_T2 = 0x0400ull, // Number of PREFETCHT1 or PREFETCHT2 instructions executed.
		SW_PREFETCH_ACCESS__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__T0 = 0x0200ull, // Number of PREFETCHT0 instructions executed.
		SW_PREFETCH_ACCESS__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__NTA = 0x0100ull, // Number of PREFETCHNTA instructions executed.
		SW_PREFETCH = 0x0032, // Software prefetches.
		SW_PREFETCH__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__PREFETCHW = 0x0800ull, // Number of PREFETCHW instructions executed.
		SW_PREFETCH__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__T1_T2 = 0x0400ull, // Number of PREFETCHT1 or PREFETCHT2 instructions executed.
		SW_PREFETCH__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__T0 = 0x0200ull, // Number of PREFETCHT0 instructions executed.
		SW_PREFETCH__MASK__INTEL_ICL_SW_PREFETCH_ACCESS__NTA = 0x0100ull, // Number of PREFETCHNTA instructions executed.
		LONGEST_LAT_CACHE = 0x002e, // L3 cache.
		LONGEST_LAT_CACHE__MASK__INTEL_ICL_LONGEST_LAT_CACHE__MISS = 0x4100ull, // Core-originated cacheable demand requests missed L3 (except hardware prefetches to L3).
		LONGEST_LAT_CACHE__MASK__INTEL_ICL_LONGEST_LAT_CACHE__REFERENCES = 0x4f00ull, // Core-originated cacheable requests that refer to L3 (Except hardware prefetches to the L3).
		CORE_POWER = 0x0028, // Power power cycles.
		CORE_POWER__MASK__INTEL_ICL_CORE_POWER__LVL2_TURBO_LICENSE = 0x2000ull, // Core cycles where the core was running in a manner where Turbo may be clipped to the AVX512 turbo schedule.
		CORE_POWER__MASK__INTEL_ICL_CORE_POWER__LVL1_TURBO_LICENSE = 0x1800ull, // Core cycles where the core was running in a manner where Turbo may be clipped to the AVX2 turbo schedule.
		CORE_POWER__MASK__INTEL_ICL_CORE_POWER__LVL0_TURBO_LICENSE = 0x0700ull, // Core cycles where the core was running in a manner where Turbo may be clipped to the Non-AVX turbo schedule.
		L2_RQSTS = 0x0024, // L2 requests.
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__ALL_DEMAND_REFERENCES = 0xe700ull, // Demand requests to L2 cache
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__ALL_CODE_RD = 0xe400ull, // L2 code requests
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__ALL_RFO = 0xe200ull, // RFO requests to L2 cache
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__ALL_DEMAND_DATA_RD = 0xe100ull, // Demand Data Read requests
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__SWPF_HIT = 0xc800ull, // SW prefetch requests that hit L2 cache. Accounts for PREFETCHNTA and PREFETCH0/1/2 instructions when FB is not full.
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__CODE_RD_HIT = 0xc400ull, // L2 cache hits when fetching instructions
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__RFO_HIT = 0xc200ull, // RFO requests that hit L2 cache
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__DEMAND_DATA_RD_HIT = 0xc100ull, // Demand Data Read requests that hit L2 cache
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__SWPF_MISS = 0x2800ull, // SW prefetch requests that miss L2 cache. Accounts for PREFETCHNTA and PREFETCH0/1/2 instructions when FB is not full.
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__ALL_DEMAND_MISS = 0x2700ull, // Demand requests that miss L2 cache
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__CODE_RD_MISS = 0x2400ull, // L2 cache misses when fetching instructions
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__RFO_MISS = 0x2200ull, // RFO requests that miss L2 cache
		L2_RQSTS__MASK__INTEL_ICL_L2_RQSTS__DEMAND_DATA_RD_MISS = 0x2100ull, // Demand Data Read miss L2
		ARITH = 0x0014, // Arithmetic uops.
		ARITH__MASK__INTEL_ICL_ARITH__DIVIDER_ACTIVE = 0x0900ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles when divide unit is busy executing divide or square root operations.
		UOPS_ISSUED = 0x000e, // Uops issued.
		UOPS_ISSUED__MASK__INTEL_ICL_UOPS_ISSUED__STALL_CYCLES = 0x0100ull | (0x1 << INTEL_X86_INV_BIT) | (0x1 << INTEL_X86_CMASK_BIT), // Cycles when RAT does not issue Uops to RS for the thread
		UOPS_ISSUED__MASK__INTEL_ICL_UOPS_ISSUED__VECTOR_WIDTH_MISMATCH = 0x0200ull, // Uops inserted at issue-stage in order to preserve upper bits of vector registers.
		UOPS_ISSUED__MASK__INTEL_ICL_UOPS_ISSUED__ANY = 0x0100ull, // Uops that RAT issues to RS
		INT_MISC = 0x000d, // Miscellaneous interruptions.
		INT_MISC__MASK__INTEL_ICL_INT_MISC__CLEAR_RESTEER_CYCLES = 0x8000ull, // Counts cycles after recovery from a branch misprediction or machine clear till the first uop is issued from the resteered path.
		INT_MISC__MASK__INTEL_ICL_INT_MISC__UOP_DROPPING = 0x1000ull, // TMA slots where uops got dropped
		INT_MISC__MASK__INTEL_ICL_INT_MISC__ALL_RECOVERY_CYCLES = 0x0300ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles the Backend cluster is recovering after a miss-speculation or a Store Buffer or Load Buffer drain stall.
		INT_MISC__MASK__INTEL_ICL_INT_MISC__RECOVERY_CYCLES = 0x0100ull, // Core cycles the allocator was stalled due to recovery from earlier clear event for this thread
		INT_MISC__MASK__INTEL_ICL_INT_MISC__CLEARS_COUNT = 0x0100ull | (0x1 << INTEL_X86_CMASK_BIT) | (0x1 << INTEL_X86_EDGE_BIT), // Clears speculative count
		DTLB_LOAD_MISSES = 0x0008, // Data TLB load misses.
		DTLB_LOAD_MISSES__MASK__INTEL_ICL_DTLB_LOAD_MISSES__STLB_HIT = 0x2000ull, // Loads that miss the DTLB and hit the STLB.
		DTLB_LOAD_MISSES__MASK__INTEL_ICL_DTLB_LOAD_MISSES__WALK_ACTIVE = 0x1000ull | (0x1 << INTEL_X86_CMASK_BIT), // Cycles when at least one PMH is busy with a page walk for a demand load.
		DTLB_LOAD_MISSES__MASK__INTEL_ICL_DTLB_LOAD_MISSES__WALK_PENDING = 0x1000ull, // Number of page walks outstanding for a demand load in the PMH each cycle.
		DTLB_LOAD_MISSES__MASK__INTEL_ICL_DTLB_LOAD_MISSES__WALK_COMPLETED = 0x0e00ull, // Load miss in all TLB levels causes a page walk that completes (All page sizes).
		DTLB_LOAD_MISSES__MASK__INTEL_ICL_DTLB_LOAD_MISSES__WALK_COMPLETED_2M_4M = 0x0400ull, // Page walks completed due to a demand data load to a 2M/4M page.
		DTLB_LOAD_MISSES__MASK__INTEL_ICL_DTLB_LOAD_MISSES__WALK_COMPLETED_4K = 0x0200ull, // Page walks completed due to a demand data load to a 4K page.
		LD_BLOCKS_PARTIAL = 0x0007, // Partial load blocks.
		LD_BLOCKS_PARTIAL__MASK__INTEL_ICL_LD_BLOCKS_PARTIAL__ADDRESS_ALIAS = 0x0100ull, // False dependencies in MOB due to partial compare on address.
		LD_BLOCKS = 0x0003, // Blocking loads.
		LD_BLOCKS__MASK__INTEL_ICL_LD_BLOCKS__NO_SR = 0x0800ull, // The number of times that split load operations are temporarily blocked because all resources for handling the split accesses are in use.
		LD_BLOCKS__MASK__INTEL_ICL_LD_BLOCKS__STORE_FORWARD = 0x0200ull, // Loads blocked due to overlapping with a preceding store that cannot be forwarded.
		TOPDOWN = 0x0000, // TMA slots available for an unhalted logical processor.
		TOPDOWN__MASK__INTEL_ICL_TOPDOWN__BR_MISPREDICT_SLOTS = 0x0800ull, // TMA slots wasted due to incorrect speculation by branch mispredictions
		TOPDOWN__MASK__INTEL_ICL_TOPDOWN__BACKEND_BOUND_SLOTS = 0x0200ull, // TMA slots where no uops were being issued due to lack of back-end resources.
		TOPDOWN__MASK__INTEL_ICL_TOPDOWN__SLOTS_P = 0x01a4ull, // TMA slots available for an unhalted logical processor. General counter - architectural event
		TOPDOWN__MASK__INTEL_ICL_TOPDOWN__SLOTS = 0x0400ull, // TMA slots available for an unhalted logical processor. Fixed counter - architectural event
		CPU_CLK_UNHALTED = 0x003c, // Count core clock cycles whenever the clock signal on the specific core is running (not halted).
		CPU_CLK_UNHALTED__MASK__INTEL_ICL_CPU_CLK_UNHALTED__DISTRIBUTED = 0x02ecull, // Cycle counts are evenly distributed between active threads in the Core.
		CPU_CLK_UNHALTED__MASK__INTEL_ICL_CPU_CLK_UNHALTED__REF_DISTRIBUTED = 0x0800ull, // Core crystal clock cycles. Cycle counts are evenly distributed between active threads in the Core.
		CPU_CLK_UNHALTED__MASK__INTEL_ICL_CPU_CLK_UNHALTED__ONE_THREAD_ACTIVE = 0x0200ull, // Core crystal clock cycles when this thread is unhalted and the other thread is halted.
		CPU_CLK_UNHALTED__MASK__INTEL_ICL_CPU_CLK_UNHALTED__REF_XCLK = 0x0100ull, // Core crystal clock cycles when the thread is unhalted.
		CPU_CLK_UNHALTED__MASK__INTEL_ICL_CPU_CLK_UNHALTED__THREAD_P = 0x0000ull, // Thread cycles when thread is not in halt state
		CPU_CLK_UNHALTED__MASK__INTEL_ICL_CPU_CLK_UNHALTED__REF_TSC = 0x0300ull, // Reference cycles when the core is not in halt state.
		INST_RETIRED = 0xc0, // Number of instructions retired
		INST_RETIRED__MASK__INTEL_ICL_INST_RETIRED__STALL_CYCLES = 0x0100ull | (0x1 << INTEL_X86_INV_BIT) | (0x1 << INTEL_X86_CMASK_BIT), // Cycles without actually retired instructions.
		INST_RETIRED__MASK__INTEL_ICL_INST_RETIRED__ANY_P = 0x0000ull, // Number of instructions retired. General Counter - architectural event
		INST_RETIRED__MASK__INTEL_ICL_INST_RETIRED__PREC_DIST = 0x0100ull, // Precise instruction retired event with a reduced effect of PEBS shadow in IP distribution (Fixed counter 0 only. c
		INST_RETIRED__MASK__INTEL_ICL_INST_RETIRED__ANY = 0x0100ull, // Number of instructions retired. Fixed Counter - architectural event (c
		INST_RETIRED__MASK__INTEL_ICL_INST_RETIRED__NOP = 0x0200ull, // Number of retired NOP instructions.
		UOPS_DECODED = 0x56, // Number of instructions decoded
		UOPS_DECODED__MASK__INTEL_ICL_UOPS_DECODED__DEC0 = 0x0100ull, // Number of uops decoded out of instructions exclusively fetched by decoder 0
		MEM_LOAD_MISC_RETIRED = 0xc4, // Miscellaneous loads retired
		MEM_LOAD_MISC_RETIRED__MASK__INTEL_ICL_MEM_LOAD_MISC_RETIRED__UC = 0x0400ull, // Retired instructions with at least 1 uncacheable load or Bus Lock.
		INST_DECODED = 0x55, // Instructions decoders
		INST_DECODED__MASK__INTEL_ICL_INST_DECODED__DECODERS = 0x0100ull, // Number of decoders utilized in a cycle when the MITE (legacy decode pipeline) fetches instructions.
		OFFCORE_RESPONSE_0 = 0x01b7, // Offcore response event
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__WRITE_ESTIMATE_MEMORY = 0xfbff8082200ull, // Counts Demand RFOs
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_MEMORY = 0x73180047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L2_ANY_RESPONSE = 0x1007000ull, // Counts hardware prefetch (which bring data to L2) that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_SOCKET_PMM = 0x700c0047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_SOCKET_DRAM = 0x70c00047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS_LOCAL_SOCKET = 0x70cc0047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_CACHE_HITM = 0x100800047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_CACHE_HITM = 0x100800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_CACHE_HITM = 0x100800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_CACHE_HITM = 0x100800000100ull, // Counts demand data reads that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_CACHE_HIT_WITH_FWD = 0x80800047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_CACHE_HIT_WITH_FWD = 0x80800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_CACHE_HIT_WITH_FWD = 0x80800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_CACHE_HIT_WITH_FWD = 0x80800000100ull, // Counts demand data reads that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__PREFETCHES_L3_HIT = 0x3f803c27f000ull, // Counts hardware and software prefetches to all cache levels that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__PREFETCHES_L3_MISS_LOCAL = 0x3f844027f000ull, // Counts hardware and software prefetches to all cache levels that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L3_L3_MISS = 0x9400238000ull, // Counts hardware prefetches to the L3 only that missed the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_MISS = 0x9400080000ull, // Counts streaming stores that missed the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS = 0x3f3fc0047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_MISS = 0x3f3fc0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__ITOM_REMOTE = 0x9000000200ull, // Counts full cacheline writes (ItoM) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L3_REMOTE = 0x9000238000ull, // Counts hardware prefetches to the L3 only that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE = 0x3f3300047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__ITOM_L3_MISS_LOCAL = 0x8400000200ull, // Counts full cacheline writes (ItoM) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L3_L3_MISS_LOCAL = 0x8400238000ull, // Counts hardware prefetches to the L3 only that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_MISS_LOCAL = 0x8400080000ull, // Counts streaming stores that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS_LOCAL = 0x3f0440047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_MISS_LOCAL = 0x3f0440000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT = 0x3f003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L3_L3_HIT = 0x8008238000ull, // Counts hardware prefetches to the L3 only that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_HIT = 0x8008080000ull, // Counts streaming stores that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_ANY_RESPONSE = 0x3f3ffc047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_ANY_RESPONSE = 0x3f3ffc000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_DRAM = 0x70800047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_DRAM = 0x70800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_DRAM = 0x70800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_DRAM = 0x70800000100ull, // Counts demand data reads that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_PMM = 0x70080047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_PMM = 0x10040047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_PMM = 0x70300047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_DRAM = 0x73000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_DRAM = 0x10400047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_DRAM = 0x73c00047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_FWD = 0x183000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_HIT_WITH_FWD = 0x83000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_HITM = 0x103000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HIT_WITH_FWD = 0x8003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HITM = 0x10003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_HIT = 0x3f803c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_HIT = 0x3f803c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_HIT = 0x3f803c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT = 0x3f803c000100ull, // Counts demand data reads that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_PMM = 0x70080000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_PMM = 0x70080000100ull, // Counts demand data reads that were supplied by PMM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__OTHER_L3_MISS_LOCAL = 0x3f8440800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_MISS_LOCAL = 0x3f8440040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_DRAM = 0x73c00040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were supplied by DRAM.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_MISS_LOCAL = 0x3f8440000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_DRAM = 0x73c00000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_PMM = 0x703c0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_LOCAL_PMM = 0x10040000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM attached to this socket
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_REMOTE_PMM = 0x70300000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM attached to another socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_DRAM = 0x73c00000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_PMM = 0x703c0000100ull, // Counts demand data reads that were supplied by PMM.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_LOCAL_PMM = 0x10040000100ull, // Counts demand data reads that were supplied by PMM attached to this socket
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_MISS_LOCAL = 0x3f8440000100ull, // Counts demand data reads that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_PMM = 0x70300000100ull, // Counts demand data reads that were supplied by PMM attached to another socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_DRAM = 0x73c00000100ull, // Counts demand data reads that were supplied by DRAM.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_CACHE_SNOOP_HIT_WITH_FWD = 0x83000000100ull, // Counts demand data reads that were supplied by a cache on a remote socket where a snoop hit in another core's caches which forwarded the unmodified data to the requesting core.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_CACHE_SNOOP_HITM = 0x103000000100ull, // Counts demand data reads that were supplied by a cache on a remote socket where a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_DRAM = 0x73000000100ull, // Counts demand data reads that were supplied by DRAM attached to another socket.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L3_ANY_RESPONSE = 0x1238000ull, // Counts hardware prefetches to the L3 only that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__OTHER_L3_MISS = 0x3fbfc0800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__OTHER_ANY_RESPONSE = 0x1800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__STREAMING_WR_ANY_RESPONSE = 0x1080000ull, // Counts streaming stores that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_LOCAL_DRAM = 0x10400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_MISS = 0x3fbfc0040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_LOCAL_DRAM = 0x10400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_MISS = 0x3fbfc0000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_ANY_RESPONSE = 0x1000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_LOCAL_DRAM = 0x10400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_LOCAL_DRAM = 0x10400000100ull, // Counts demand data reads that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_MISS = 0x3fbfc0000100ull, // Counts demand data reads that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_ANY_RESPONSE = 0x1000100ull, // Counts demand data reads that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HITM = 0x10003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_HIT_SNOOP_HITM = 0x10003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_WITH_FWD = 0x8003c000100ull, // Counts demand data reads that resulted in a snoop hit in another core's caches which forwarded the unmodified data to the requesting core.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c000100ull, // Counts demand data reads that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000100ull, // Counts demand data reads that resulted in a snoop that hit in another core
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_LOCAL_DRAM = 0x18400800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__STREAMING_WR_LOCAL_DRAM = 0x18400080000ull, // Counts streaming stores that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_LOCAL_DRAM = 0x18400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_LOCAL_DRAM = 0x18400002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_LOCAL_DRAM = 0x18400001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_LOCAL_DRAM = 0x18400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_LOCAL_DRAM = 0x18400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_LOCAL_DRAM = 0x18400000100ull, // Counts demand data reads that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_L3_MISS = 0x3fffc0800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__STREAMING_WR_L3_MISS = 0x3fffc0080000ull, // Counts streaming stores that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_MISS = 0x3fffc0040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_MISS = 0x3fffc0002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_MISS = 0x3fffc0001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_MISS = 0x3fffc0000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_MISS = 0x3fffc0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_MISS = 0x3fffc0000100ull, // Counts demand data reads that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_DRAM = 0x18400800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__STREAMING_WR_DRAM = 0x18400080000ull, // Counts streaming stores that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_DRAM = 0x18400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_DRAM = 0x18400002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_DRAM = 0x18400001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_DRAM = 0x18400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_DRAM = 0x18400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_DRAM = 0x18400000100ull, // Counts demand data reads that DRAM supplied the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_SENT = 0x1e003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_SENT = 0x1e003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_SENT = 0x1e003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_SENT = 0x1e003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_SENT = 0x1e003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_SENT = 0x1e003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_ANY_RESPONSE = 0x1800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__STREAMING_WR_ANY_RESPONSE = 0x1080000ull, // Counts streaming stores that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_ANY_RESPONSE = 0x1040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_ANY_RESPONSE = 0x1002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_ANY_RESPONSE = 0x1001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_ANY_RESPONSE = 0x1000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_ANY_RESPONSE = 0x1000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_ANY_RESPONSE = 0x1000100ull, // Counts demand data reads that have any type of response.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L3_L3_HIT_ANY = 0x3fc03c238000ull, // Counts hardware prefetches to the L3 only that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_MISS = 0x2003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__STREAMING_WR_L3_HIT_ANY = 0x3fc03c080000ull, // Counts streaming stores that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_ANY = 0x3fc03c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_SNOOP_MISS = 0x2003c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_ANY = 0x3fc03c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_HITM = 0x10003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_MISS = 0x2003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_ANY = 0x3fc03c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_MISS = 0x2003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_ANY = 0x3fc03c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HITM = 0x10003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_MISS = 0x2003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_ANY = 0x3fc03c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_HITM = 0x10003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_MISS = 0x2003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_ANY = 0x3fc03c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_MISS = 0x2003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_0__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_1 = 0x01bb, // Offcore response event
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__WRITE_ESTIMATE_MEMORY = 0xfbff8082200ull, // Counts Demand RFOs
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_MEMORY = 0x73180047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L2_ANY_RESPONSE = 0x1007000ull, // Counts hardware prefetch (which bring data to L2) that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_SOCKET_PMM = 0x700c0047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_SOCKET_DRAM = 0x70c00047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS_LOCAL_SOCKET = 0x70cc0047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_CACHE_HITM = 0x100800047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_CACHE_HITM = 0x100800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_CACHE_HITM = 0x100800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_CACHE_HITM = 0x100800000100ull, // Counts demand data reads that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_CACHE_HIT_WITH_FWD = 0x80800047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_CACHE_HIT_WITH_FWD = 0x80800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_CACHE_HIT_WITH_FWD = 0x80800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_CACHE_HIT_WITH_FWD = 0x80800000100ull, // Counts demand data reads that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__PREFETCHES_L3_HIT = 0x3f803c27f000ull, // Counts hardware and software prefetches to all cache levels that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__PREFETCHES_L3_MISS_LOCAL = 0x3f844027f000ull, // Counts hardware and software prefetches to all cache levels that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L3_L3_MISS = 0x9400238000ull, // Counts hardware prefetches to the L3 only that missed the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_MISS = 0x9400080000ull, // Counts streaming stores that missed the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS = 0x3f3fc0047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_MISS = 0x3f3fc0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__ITOM_REMOTE = 0x9000000200ull, // Counts full cacheline writes (ItoM) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L3_REMOTE = 0x9000238000ull, // Counts hardware prefetches to the L3 only that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE = 0x3f3300047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__ITOM_L3_MISS_LOCAL = 0x8400000200ull, // Counts full cacheline writes (ItoM) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L3_L3_MISS_LOCAL = 0x8400238000ull, // Counts hardware prefetches to the L3 only that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_MISS_LOCAL = 0x8400080000ull, // Counts streaming stores that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS_LOCAL = 0x3f0440047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_MISS_LOCAL = 0x3f0440000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT = 0x3f003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L3_L3_HIT = 0x8008238000ull, // Counts hardware prefetches to the L3 only that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_HIT = 0x8008080000ull, // Counts streaming stores that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_ANY_RESPONSE = 0x3f3ffc047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_ANY_RESPONSE = 0x3f3ffc000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_DRAM = 0x70800047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_DRAM = 0x70800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_DRAM = 0x70800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_DRAM = 0x70800000100ull, // Counts demand data reads that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_PMM = 0x70080047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_PMM = 0x10040047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_PMM = 0x70300047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_DRAM = 0x73000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_DRAM = 0x10400047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_DRAM = 0x73c00047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_FWD = 0x183000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_HIT_WITH_FWD = 0x83000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_HITM = 0x103000047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HIT_WITH_FWD = 0x8003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HITM = 0x10003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c047700ull, // Counts all (cacheable) data read
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_HIT = 0x3f803c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_HIT = 0x3f803c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_HIT = 0x3f803c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT = 0x3f803c000100ull, // Counts demand data reads that hit in the L3 or were snooped from another core's caches on the same socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_PMM = 0x70080000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_PMM = 0x70080000100ull, // Counts demand data reads that were supplied by PMM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__OTHER_L3_MISS_LOCAL = 0x3f8440800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_MISS_LOCAL = 0x3f8440040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_DRAM = 0x73c00040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were supplied by DRAM.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_MISS_LOCAL = 0x3f8440000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_DRAM = 0x73c00000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_PMM = 0x703c0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_LOCAL_PMM = 0x10040000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM attached to this socket
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_REMOTE_PMM = 0x70300000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM attached to another socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_DRAM = 0x73c00000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_PMM = 0x703c0000100ull, // Counts demand data reads that were supplied by PMM.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_LOCAL_PMM = 0x10040000100ull, // Counts demand data reads that were supplied by PMM attached to this socket
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_MISS_LOCAL = 0x3f8440000100ull, // Counts demand data reads that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_PMM = 0x70300000100ull, // Counts demand data reads that were supplied by PMM attached to another socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_DRAM = 0x73c00000100ull, // Counts demand data reads that were supplied by DRAM.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_CACHE_SNOOP_HIT_WITH_FWD = 0x83000000100ull, // Counts demand data reads that were supplied by a cache on a remote socket where a snoop hit in another core's caches which forwarded the unmodified data to the requesting core.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_CACHE_SNOOP_HITM = 0x103000000100ull, // Counts demand data reads that were supplied by a cache on a remote socket where a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_DRAM = 0x73000000100ull, // Counts demand data reads that were supplied by DRAM attached to another socket.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L3_ANY_RESPONSE = 0x1238000ull, // Counts hardware prefetches to the L3 only that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__OTHER_L3_MISS = 0x3fbfc0800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__OTHER_ANY_RESPONSE = 0x1800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__STREAMING_WR_ANY_RESPONSE = 0x1080000ull, // Counts streaming stores that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_LOCAL_DRAM = 0x10400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_MISS = 0x3fbfc0040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_LOCAL_DRAM = 0x10400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_MISS = 0x3fbfc0000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_ANY_RESPONSE = 0x1000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_LOCAL_DRAM = 0x10400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_LOCAL_DRAM = 0x10400000100ull, // Counts demand data reads that were supplied by DRAM attached to this socket
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_MISS = 0x3fbfc0000100ull, // Counts demand data reads that were not supplied by the local socket's L1
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_ANY_RESPONSE = 0x1000100ull, // Counts demand data reads that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HITM = 0x10003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_HIT_SNOOP_HITM = 0x10003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_WITH_FWD = 0x8003c000100ull, // Counts demand data reads that resulted in a snoop hit in another core's caches which forwarded the unmodified data to the requesting core.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c000100ull, // Counts demand data reads that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000100ull, // Counts demand data reads that resulted in a snoop that hit in another core
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_LOCAL_DRAM = 0x18400800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__STREAMING_WR_LOCAL_DRAM = 0x18400080000ull, // Counts streaming stores that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_LOCAL_DRAM = 0x18400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_LOCAL_DRAM = 0x18400002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_LOCAL_DRAM = 0x18400001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_LOCAL_DRAM = 0x18400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_LOCAL_DRAM = 0x18400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_LOCAL_DRAM = 0x18400000100ull, // Counts demand data reads that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_L3_MISS = 0x3fffc0800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__STREAMING_WR_L3_MISS = 0x3fffc0080000ull, // Counts streaming stores that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_MISS = 0x3fffc0040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_MISS = 0x3fffc0002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_MISS = 0x3fffc0001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_MISS = 0x3fffc0000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_MISS = 0x3fffc0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_MISS = 0x3fffc0000100ull, // Counts demand data reads that was not supplied by the L3 cache.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_DRAM = 0x18400800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__STREAMING_WR_DRAM = 0x18400080000ull, // Counts streaming stores that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_DRAM = 0x18400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_DRAM = 0x18400002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_DRAM = 0x18400001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_DRAM = 0x18400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_DRAM = 0x18400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_DRAM = 0x18400000100ull, // Counts demand data reads that DRAM supplied the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_SENT = 0x1e003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_SENT = 0x1e003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_SENT = 0x1e003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_SENT = 0x1e003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_SENT = 0x1e003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_SENT = 0x1e003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_ANY_RESPONSE = 0x1800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__STREAMING_WR_ANY_RESPONSE = 0x1080000ull, // Counts streaming stores that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_ANY_RESPONSE = 0x1040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_ANY_RESPONSE = 0x1002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_ANY_RESPONSE = 0x1001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_ANY_RESPONSE = 0x1000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_ANY_RESPONSE = 0x1000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_ANY_RESPONSE = 0x1000100ull, // Counts demand data reads that have any type of response.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L3_L3_HIT_ANY = 0x3fc03c238000ull, // Counts hardware prefetches to the L3 only that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_MISS = 0x2003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c800000ull, // Counts miscellaneous requests
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__STREAMING_WR_L3_HIT_ANY = 0x3fc03c080000ull, // Counts streaming stores that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_ANY = 0x3fc03c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_SNOOP_MISS = 0x2003c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_ANY = 0x3fc03c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_HITM = 0x10003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_MISS = 0x2003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_ANY = 0x3fc03c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_MISS = 0x2003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_ANY = 0x3fc03c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HITM = 0x10003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_MISS = 0x2003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_ANY = 0x3fc03c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_HITM = 0x10003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_MISS = 0x2003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_ANY = 0x3fc03c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent or not.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop hit in another cores caches
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop hit in another core
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_MISS = 0x2003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OFFCORE_RESPONSE_1__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OCR = 0x01b7, // Offcore response event
		OCR__MASK__INTEL_ICX_OCR__WRITE_ESTIMATE_MEMORY = 0xfbff8082200ull, // Counts Demand RFOs
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_MEMORY = 0x73180047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__HWPF_L2_ANY_RESPONSE = 0x1007000ull, // Counts hardware prefetch (which bring data to L2) that have any type of response.
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_SOCKET_PMM = 0x700c0047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_SOCKET_DRAM = 0x70c00047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS_LOCAL_SOCKET = 0x70cc0047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_CACHE_HITM = 0x100800047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_CACHE_HITM = 0x100800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_CACHE_HITM = 0x100800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_CACHE_HITM = 0x100800000100ull, // Counts demand data reads that hit a modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_CACHE_HIT_WITH_FWD = 0x80800047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_CACHE_HIT_WITH_FWD = 0x80800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_CACHE_HIT_WITH_FWD = 0x80800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_CACHE_HIT_WITH_FWD = 0x80800000100ull, // Counts demand data reads that either hit a non-modified line in a distant L3 Cache or were snooped from a distant core's L1/L2 caches on this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__PREFETCHES_L3_HIT = 0x3f803c27f000ull, // Counts hardware and software prefetches to all cache levels that hit in the L3 or were snooped from another core's caches on the same socket.
		OCR__MASK__INTEL_ICX_OCR__PREFETCHES_L3_MISS_LOCAL = 0x3f844027f000ull, // Counts hardware and software prefetches to all cache levels that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__HWPF_L3_L3_MISS = 0x9400238000ull, // Counts hardware prefetches to the L3 only that missed the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_MISS = 0x9400080000ull, // Counts streaming stores that missed the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS = 0x3f3fc0047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_MISS = 0x3f3fc0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__ITOM_REMOTE = 0x9000000200ull, // Counts full cacheline writes (ItoM) that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__HWPF_L3_REMOTE = 0x9000238000ull, // Counts hardware prefetches to the L3 only that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE = 0x3f3300047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__ITOM_L3_MISS_LOCAL = 0x8400000200ull, // Counts full cacheline writes (ItoM) that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__HWPF_L3_L3_MISS_LOCAL = 0x8400238000ull, // Counts hardware prefetches to the L3 only that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_MISS_LOCAL = 0x8400080000ull, // Counts streaming stores that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_MISS_LOCAL = 0x3f0440047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_MISS_LOCAL = 0x3f0440000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT = 0x3f003c047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__HWPF_L3_L3_HIT = 0x8008238000ull, // Counts hardware prefetches to the L3 only that hit in the L3 or were snooped from another core's caches on the same socket.
		OCR__MASK__INTEL_ICX_OCR__STREAMING_WR_L3_HIT = 0x8008080000ull, // Counts streaming stores that hit in the L3 or were snooped from another core's caches on the same socket.
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_ANY_RESPONSE = 0x3f3ffc047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_ANY_RESPONSE = 0x3f3ffc000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that have any type of response.
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_DRAM = 0x70800047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_SNC_DRAM = 0x70800000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_DRAM = 0x70800000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_DRAM = 0x70800000100ull, // Counts demand data reads that were supplied by DRAM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_SNC_PMM = 0x70080047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_PMM = 0x10040047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_PMM = 0x70300047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_DRAM = 0x73000047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_LOCAL_DRAM = 0x10400047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_DRAM = 0x73c00047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_FWD = 0x183000047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_HIT_WITH_FWD = 0x83000047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_REMOTE_CACHE_SNOOP_HITM = 0x103000047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HIT_WITH_FWD = 0x8003c047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HITM = 0x10003c047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__READS_TO_CORE_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c047700ull, // Counts all (cacheable) data read
		OCR__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_HIT = 0x3f803c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit in the L3 or were snooped from another core's caches on the same socket.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_HIT = 0x3f803c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit in the L3 or were snooped from another core's caches on the same socket.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_HIT = 0x3f803c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit in the L3 or were snooped from another core's caches on the same socket.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT = 0x3f803c000100ull, // Counts demand data reads that hit in the L3 or were snooped from another core's caches on the same socket.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_SNC_PMM = 0x70080000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_SNC_PMM = 0x70080000100ull, // Counts demand data reads that were supplied by PMM on a distant memory controller of this socket when the system is in SNC (sub-NUMA cluster) mode.
		OCR__MASK__INTEL_ICX_OCR__OTHER_L3_MISS_LOCAL = 0x3f8440800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_MISS_LOCAL = 0x3f8440040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_DRAM = 0x73c00040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were supplied by DRAM.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_MISS_LOCAL = 0x3f8440000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_DRAM = 0x73c00000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_PMM = 0x703c0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_LOCAL_PMM = 0x10040000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM attached to this socket
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_REMOTE_PMM = 0x70300000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by PMM attached to another socket.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_DRAM = 0x73c00000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_PMM = 0x703c0000100ull, // Counts demand data reads that were supplied by PMM.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_LOCAL_PMM = 0x10040000100ull, // Counts demand data reads that were supplied by PMM attached to this socket
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_MISS_LOCAL = 0x3f8440000100ull, // Counts demand data reads that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_PMM = 0x70300000100ull, // Counts demand data reads that were supplied by PMM attached to another socket.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_DRAM = 0x73c00000100ull, // Counts demand data reads that were supplied by DRAM.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_CACHE_SNOOP_HIT_WITH_FWD = 0x83000000100ull, // Counts demand data reads that were supplied by a cache on a remote socket where a snoop hit in another core's caches which forwarded the unmodified data to the requesting core.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_CACHE_SNOOP_HITM = 0x103000000100ull, // Counts demand data reads that were supplied by a cache on a remote socket where a snoop hit a modified line in another core's caches which forwarded the data.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_REMOTE_DRAM = 0x73000000100ull, // Counts demand data reads that were supplied by DRAM attached to another socket.
		OCR__MASK__INTEL_ICX_OCR__HWPF_L3_ANY_RESPONSE = 0x1238000ull, // Counts hardware prefetches to the L3 only that have any type of response.
		OCR__MASK__INTEL_ICX_OCR__OTHER_L3_MISS = 0x3fbfc0800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICX_OCR__OTHER_ANY_RESPONSE = 0x1800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICX_OCR__STREAMING_WR_ANY_RESPONSE = 0x1080000ull, // Counts streaming stores that have any type of response.
		OCR__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_LOCAL_DRAM = 0x10400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were supplied by DRAM attached to this socket
		OCR__MASK__INTEL_ICX_OCR__HWPF_L1D_AND_SWPF_L3_MISS = 0x3fbfc0040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_LOCAL_DRAM = 0x10400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were supplied by DRAM attached to this socket
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_MISS = 0x3fbfc0000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_ANY_RESPONSE = 0x1000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that have any type of response.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_LOCAL_DRAM = 0x10400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that were supplied by DRAM attached to this socket
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_LOCAL_DRAM = 0x10400000100ull, // Counts demand data reads that were supplied by DRAM attached to this socket
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_MISS = 0x3fbfc0000100ull, // Counts demand data reads that were not supplied by the local socket's L1
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_ANY_RESPONSE = 0x1000100ull, // Counts demand data reads that have any type of response.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HITM = 0x10003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_RFO_L3_HIT_SNOOP_HITM = 0x10003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_WITH_FWD = 0x8003c000100ull, // Counts demand data reads that resulted in a snoop hit in another core's caches which forwarded the unmodified data to the requesting core.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c000100ull, // Counts demand data reads that resulted in a snoop hit a modified line in another core's caches which forwarded the data.
		OCR__MASK__INTEL_ICX_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000100ull, // Counts demand data reads that resulted in a snoop that hit in another core
		OCR__MASK__INTEL_ICL_OCR__OTHER_LOCAL_DRAM = 0x18400800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__STREAMING_WR_LOCAL_DRAM = 0x18400080000ull, // Counts streaming stores that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_LOCAL_DRAM = 0x18400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_LOCAL_DRAM = 0x18400002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_LOCAL_DRAM = 0x18400001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_LOCAL_DRAM = 0x18400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_LOCAL_DRAM = 0x18400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_LOCAL_DRAM = 0x18400000100ull, // Counts demand data reads that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__OTHER_L3_MISS = 0x3fffc0800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__STREAMING_WR_L3_MISS = 0x3fffc0080000ull, // Counts streaming stores that was not supplied by the L3 cache.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_MISS = 0x3fffc0040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that was not supplied by the L3 cache.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_MISS = 0x3fffc0002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that was not supplied by the L3 cache.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_MISS = 0x3fffc0001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that was not supplied by the L3 cache.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_MISS = 0x3fffc0000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that was not supplied by the L3 cache.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_MISS = 0x3fffc0000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that was not supplied by the L3 cache.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_MISS = 0x3fffc0000100ull, // Counts demand data reads that was not supplied by the L3 cache.
		OCR__MASK__INTEL_ICL_OCR__OTHER_DRAM = 0x18400800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__STREAMING_WR_DRAM = 0x18400080000ull, // Counts streaming stores that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_DRAM = 0x18400040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_DRAM = 0x18400002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_DRAM = 0x18400001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_DRAM = 0x18400000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_DRAM = 0x18400000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_DRAM = 0x18400000100ull, // Counts demand data reads that DRAM supplied the request.
		OCR__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_SENT = 0x1e003c800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_SENT = 0x1e003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_SENT = 0x1e003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_SENT = 0x1e003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_SENT = 0x1e003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_SENT = 0x1e003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent.
		OCR__MASK__INTEL_ICL_OCR__OTHER_ANY_RESPONSE = 0x1800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__STREAMING_WR_ANY_RESPONSE = 0x1080000ull, // Counts streaming stores that have any type of response.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_ANY_RESPONSE = 0x1040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that have any type of response.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_ANY_RESPONSE = 0x1002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that have any type of response.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_ANY_RESPONSE = 0x1001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that have any type of response.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_ANY_RESPONSE = 0x1000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that have any type of response.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_ANY_RESPONSE = 0x1000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that have any type of response.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_ANY_RESPONSE = 0x1000100ull, // Counts demand data reads that have any type of response.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L3_L3_HIT_ANY = 0x3fc03c238000ull, // Counts hardware prefetches to the L3 only that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_MISS = 0x2003c800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__OTHER_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c800000ull, // Counts miscellaneous requests
		OCR__MASK__INTEL_ICL_OCR__STREAMING_WR_L3_HIT_ANY = 0x3fc03c080000ull, // Counts streaming stores that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_ANY = 0x3fc03c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_SNOOP_MISS = 0x2003c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L1D_AND_SWPF_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c040000ull, // Counts L1 data cache prefetch requests and software prefetches (except PREFETCHW) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_ANY = 0x3fc03c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_HITM = 0x10003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop hit in another cores caches
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop hit in another core
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_MISS = 0x2003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_RFO_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c002000ull, // Counts hardware prefetch RFOs (which bring data to L2) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_ANY = 0x3fc03c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop hit in another cores caches
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop hit in another core
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_MISS = 0x2003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OCR__MASK__INTEL_ICL_OCR__HWPF_L2_DATA_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c001000ull, // Counts hardware prefetch data reads (which bring data to L2)  that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_ANY = 0x3fc03c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HITM = 0x10003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop hit in another cores caches
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop hit in another core
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_MISS = 0x2003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_CODE_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000400ull, // Counts demand instruction fetches and L1 instruction cache prefetches that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_ANY = 0x3fc03c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_HITM = 0x10003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop hit in another cores caches
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop hit in another core
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_MISS = 0x2003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_RFO_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000200ull, // Counts demand reads for ownership (RFO) requests and software prefetches for exclusive ownership (PREFETCHW) that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_ANY = 0x3fc03c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent or not.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HITM = 0x10003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop hit in another cores caches
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_HIT_NO_FWD = 0x4003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop hit in another core
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_MISS = 0x2003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was sent but no other cores had the data.
		OCR__MASK__INTEL_ICL_OCR__DEMAND_DATA_RD_L3_HIT_SNOOP_NOT_NEEDED = 0x1003c000100ull, // Counts demand data reads that hit a cacheline in the L3 where a snoop was not needed to satisfy the request.
		
	};
};

namespace icl = optkit::intel::icl;